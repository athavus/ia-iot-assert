{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "## Exerc√≠cio 1 - Problema do XOR\n",
        "\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "import numpy as np\n",
        "\n",
        "x = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "y = np.array([0, 1, 1, 0])\n",
        "\n",
        "# 1- Importar o modelo MLP do sklearn\n",
        "# 2- Instanciar o modelo escolhendo uma topologia para a rede, fun√ß√£o de ativa√ß√£o e n√∫mero de √©pocas de execu√ß√£o at√© 100% de acerto\n",
        "# 3- Treinar o modelo com os dados de treinamento\n",
        "# 4- Fazer o predict com os dados de treinamento\n",
        "# 5- Comparar o resultado do predict com o vetor y"
      ],
      "metadata": {
        "id": "Q8khw7gpctj0"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importa√ß√£o das bibliotecas necess√°rias\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import validation_curve\n",
        "\n",
        "# === PROBLEMA XOR - DEFINI√á√ÉO DOS DADOS ===\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"           AN√ÅLISE DE REDE NEURAL MLP - PROBLEMA XOR\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Defini√ß√£o dos dados de entrada (problema XOR cl√°ssico)\n",
        "# XOR √© um problema n√£o-linearmente separ√°vel, ideal para demonstrar redes neurais\n",
        "dados_entrada = np.array([\n",
        "    [0, 0],  # Entrada 1: 0 XOR 0 = 0\n",
        "    [0, 1],  # Entrada 2: 0 XOR 1 = 1\n",
        "    [1, 0],  # Entrada 3: 1 XOR 0 = 1\n",
        "    [1, 1]   # Entrada 4: 1 XOR 1 = 0\n",
        "])\n",
        "\n",
        "# Sa√≠das esperadas para o problema XOR\n",
        "saidas_esperadas = np.array([0, 1, 1, 0])\n",
        "\n",
        "print(\"üéØ PROBLEMA: Porta L√≥gica XOR (Exclusive OR)\")\n",
        "print(\"üìä DADOS DE TREINAMENTO:\")\n",
        "print(\"   Entrada  |  Sa√≠da Esperada\")\n",
        "print(\"   ---------|----------------\")\n",
        "for i, (entrada, saida) in enumerate(zip(dados_entrada, saidas_esperadas)):\n",
        "    print(f\"   {entrada}     |       {saida}\")\n",
        "\n",
        "print(f\"\\nüìè DIMENS√ïES:\")\n",
        "print(f\"   ‚Ä¢ Dados de entrada: {dados_entrada.shape}\")\n",
        "print(f\"   ‚Ä¢ Sa√≠das esperadas: {saidas_esperadas.shape}\")\n",
        "print(f\"   ‚Ä¢ N√∫mero de features: {dados_entrada.shape[1]}\")\n",
        "print(f\"   ‚Ä¢ N√∫mero de amostras: {dados_entrada.shape[0]}\")\n",
        "\n",
        "# === CONFIGURA√á√ÉO DA REDE NEURAL MLP ===\n",
        "\n",
        "print(f\"\\n\" + \"=\"*60)\n",
        "print(\"              CONFIGURA√á√ÉO DA REDE NEURAL\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Par√¢metros da rede neural\n",
        "camadas_ocultas = (4,)  # Uma camada oculta com 4 neur√¥nios\n",
        "funcao_ativacao = 'logistic'  # Fun√ß√£o sigmoide\n",
        "max_iteracoes = 10000\n",
        "semente_aleatoria = 42\n",
        "\n",
        "print(\"üß† ARQUITETURA DA REDE:\")\n",
        "print(f\"   ‚Ä¢ Camada de entrada: {dados_entrada.shape[1]} neur√¥nios\")\n",
        "print(f\"   ‚Ä¢ Camadas ocultas: {camadas_ocultas} neur√¥nios\")\n",
        "print(f\"   ‚Ä¢ Camada de sa√≠da: 1 neur√¥nio\")\n",
        "print(f\"   ‚Ä¢ Total de camadas: {len(camadas_ocultas) + 2} (entrada + oculta + sa√≠da)\")\n",
        "\n",
        "print(f\"\\n‚öôÔ∏è  HIPERPAR√ÇMETROS:\")\n",
        "print(f\"   ‚Ä¢ Fun√ß√£o de ativa√ß√£o: {funcao_ativacao} (sigm√≥ide)\")\n",
        "print(f\"   ‚Ä¢ M√°ximo de itera√ß√µes: {max_iteracoes:,}\")\n",
        "print(f\"   ‚Ä¢ Semente aleat√≥ria: {semente_aleatoria}\")\n",
        "print(f\"   ‚Ä¢ Solver: adam (otimizador padr√£o)\")\n",
        "\n",
        "# Cria√ß√£o e configura√ß√£o do modelo MLP\n",
        "modelo_mlp = MLPClassifier(\n",
        "    hidden_layer_sizes=camadas_ocultas,\n",
        "    activation=funcao_ativacao,\n",
        "    max_iter=max_iteracoes,\n",
        "    random_state=semente_aleatoria,\n",
        "    solver='adam'  # Otimizador Adam (padr√£o, eficiente)\n",
        ")\n",
        "\n",
        "# === TREINAMENTO DA REDE NEURAL ===\n",
        "\n",
        "print(f\"\\n\" + \"=\"*60)\n",
        "print(\"                TREINAMENTO DA REDE\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"üîÑ Iniciando treinamento...\")\n",
        "\n",
        "# Treinamento do modelo\n",
        "modelo_mlp.fit(dados_entrada, saidas_esperadas)\n",
        "\n",
        "print(\"‚úÖ Treinamento conclu√≠do!\")\n",
        "print(f\"üìà N√∫mero de itera√ß√µes realizadas: {modelo_mlp.n_iter_}\")\n",
        "print(f\"üéØ Converg√™ncia alcan√ßada: {'Sim' if modelo_mlp.n_iter_ < max_iteracoes else 'N√£o'}\")\n",
        "\n",
        "# === PREDI√á√ïES E AVALIA√á√ÉO ===\n",
        "\n",
        "print(f\"\\n\" + \"=\"*60)\n",
        "print(\"              RESULTADOS E AVALIA√á√ÉO\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Fazer predi√ß√µes nos dados de treinamento\n",
        "predicoes_mlp = modelo_mlp.predict(dados_entrada)\n",
        "\n",
        "# Obter probabilidades das predi√ß√µes\n",
        "probabilidades_predicao = modelo_mlp.predict_proba(dados_entrada)\n",
        "\n",
        "# C√°lculo da acur√°cia\n",
        "acuracia_modelo = modelo_mlp.score(dados_entrada, saidas_esperadas)\n",
        "\n",
        "print(\"üìä COMPARA√á√ÉO DETALHADA:\")\n",
        "print(\"   Entrada  | Esperado | Predito | Probabilidade [Classe 0, Classe 1] | Correto?\")\n",
        "print(\"   ---------|----------|---------|-------------------------------------|----------\")\n",
        "\n",
        "for i, (entrada, esperado, predito, prob) in enumerate(zip(dados_entrada, saidas_esperadas, predicoes_mlp, probabilidades_predicao)):\n",
        "    correto = \"‚úÖ\" if esperado == predito else \"‚ùå\"\n",
        "    print(f\"   {entrada}     |    {esperado}     |    {predito}    | [{prob[0]:.4f}, {prob[1]:.4f}]              |    {correto}\")\n",
        "\n",
        "print(f\"\\nüéØ M√âTRICAS DE DESEMPENHO:\")\n",
        "print(f\"   ‚Ä¢ Acur√°cia: {acuracia_modelo*100:.1f}%\")\n",
        "print(f\"   ‚Ä¢ Erro: {(1-acuracia_modelo)*100:.1f}%\")\n",
        "\n",
        "# === AN√ÅLISE DETALHADA DO MODELO ===\n",
        "\n",
        "print(f\"\\n\" + \"=\"*60)\n",
        "print(\"              AN√ÅLISE DETALHADA DO MODELO\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Relat√≥rio de classifica√ß√£o\n",
        "print(\"üìã RELAT√ìRIO DE CLASSIFICA√á√ÉO:\")\n",
        "relatorio_classificacao = classification_report(\n",
        "    saidas_esperadas,\n",
        "    predicoes_mlp,\n",
        "    target_names=['Classe 0 (False)', 'Classe 1 (True)'],\n",
        "    zero_division=0\n",
        ")\n",
        "print(relatorio_classificacao)\n",
        "\n",
        "# Matriz de confus√£o\n",
        "print(\"üéØ MATRIZ DE CONFUS√ÉO:\")\n",
        "matriz_confusao = confusion_matrix(saidas_esperadas, predicoes_mlp)\n",
        "print(\"         Predito\")\n",
        "print(\"        0    1\")\n",
        "print(\"Real 0 \", matriz_confusao[0])\n",
        "print(\"Real 1 \", matriz_confusao[1])\n",
        "\n",
        "# Informa√ß√µes sobre a arquitetura treinada\n",
        "print(f\"\\nüèóÔ∏è  DETALHES DA ARQUITETURA TREINADA:\")\n",
        "print(f\"   ‚Ä¢ N√∫mero de camadas: {modelo_mlp.n_layers_}\")\n",
        "print(f\"   ‚Ä¢ N√∫mero de sa√≠das: {modelo_mlp.n_outputs_}\")\n",
        "\n",
        "# Pesos e biases (se desejado visualizar a estrutura interna)\n",
        "print(f\"\\n‚öñÔ∏è  INFORMA√á√ïES DOS PESOS:\")\n",
        "for i, (pesos, bias) in enumerate(zip(modelo_mlp.coefs_, modelo_mlp.intercepts_)):\n",
        "    camada = f\"Entrada ‚Üí Oculta\" if i == 0 else f\"Oculta {i} ‚Üí Sa√≠da\"\n",
        "    print(f\"   ‚Ä¢ {camada}: Matriz {pesos.shape}, Bias {bias.shape}\")\n",
        "\n",
        "# === AN√ÅLISE DA FUN√á√ÉO DE PERDA ===\n",
        "\n",
        "print(f\"\\nüìâ EVOLU√á√ÉO DO TREINAMENTO:\")\n",
        "if hasattr(modelo_mlp, 'loss_curve_'):\n",
        "    print(f\"   ‚Ä¢ Perda inicial: {modelo_mlp.loss_curve_[0]:.6f}\")\n",
        "    print(f\"   ‚Ä¢ Perda final: {modelo_mlp.loss_curve_[-1]:.6f}\")\n",
        "    print(f\"   ‚Ä¢ Redu√ß√£o da perda: {modelo_mlp.loss_curve_[0] - modelo_mlp.loss_curve_[-1]:.6f}\")\n",
        "else:\n",
        "    print(\"   ‚Ä¢ Curva de perda n√£o dispon√≠vel\")\n",
        "\n",
        "# === TESTE COM DIFERENTES CONFIGURA√á√ïES ===\n",
        "\n",
        "print(f\"\\n\" + \"=\"*60)\n",
        "print(\"          COMPARA√á√ÉO COM OUTRAS CONFIGURA√á√ïES\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Testando diferentes tamanhos de camadas ocultas\n",
        "configuracoes_teste = [\n",
        "    (2,), (3,), (4,), (5,), (8,),\n",
        "    (2, 2), (4, 2), (3, 3)\n",
        "]\n",
        "\n",
        "print(\"üî¨ TESTE DE DIFERENTES ARQUITETURAS:\")\n",
        "print(\"   Arquitetura    | Itera√ß√µes | Acur√°cia\")\n",
        "print(\"   ---------------|-----------|----------\")\n",
        "\n",
        "melhores_resultados = []\n",
        "\n",
        "for config in configuracoes_teste:\n",
        "    modelo_teste = MLPClassifier(\n",
        "        hidden_layer_sizes=config,\n",
        "        activation='logistic',\n",
        "        max_iter=10000,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    modelo_teste.fit(dados_entrada, saidas_esperadas)\n",
        "    acuracia_teste = modelo_teste.score(dados_entrada, saidas_esperadas)\n",
        "\n",
        "    melhores_resultados.append((config, modelo_teste.n_iter_, acuracia_teste))\n",
        "\n",
        "    config_str = f\"({', '.join(map(str, config))})\"\n",
        "    print(f\"   {config_str:<14} | {modelo_teste.n_iter_:>8} | {acuracia_teste*100:>6.1f}%\")\n",
        "\n",
        "# Melhor configura√ß√£o\n",
        "melhor_config = max(melhores_resultados, key=lambda x: (x[2], -x[1]))\n",
        "print(f\"\\nüèÜ MELHOR CONFIGURA√á√ÉO:\")\n",
        "print(f\"   ‚Ä¢ Arquitetura: {melhor_config[0]}\")\n",
        "print(f\"   ‚Ä¢ Itera√ß√µes: {melhor_config[1]}\")\n",
        "print(f\"   ‚Ä¢ Acur√°cia: {melhor_config[2]*100:.1f}%\")\n",
        "\n",
        "# === INSIGHTS E CONCLUS√ïES ===\n",
        "\n",
        "print(f\"\\n\" + \"=\"*60)\n",
        "print(\"              INSIGHTS E CONCLUS√ïES\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"üí° OBSERVA√á√ïES IMPORTANTES:\")\n",
        "print(\"   ‚Ä¢ O problema XOR √© n√£o-linearmente separ√°vel\")\n",
        "print(\"   ‚Ä¢ Perceptrons simples n√£o conseguem resolver XOR\")\n",
        "print(\"   ‚Ä¢ MLPs com camadas ocultas resolvem o problema facilmente\")\n",
        "print(\"   ‚Ä¢ A fun√ß√£o sigmoide permite n√£o-linearidade necess√°ria\")\n",
        "\n",
        "print(f\"\\nüéì LI√á√ïES APRENDIDAS:\")\n",
        "print(\"   ‚Ä¢ Import√¢ncia das camadas ocultas para problemas n√£o-lineares\")\n",
        "print(\"   ‚Ä¢ Fun√ß√£o de ativa√ß√£o sigm√≥ide adequada para classifica√ß√£o bin√°ria\")\n",
        "print(\"   ‚Ä¢ Poucas itera√ß√µes necess√°rias para converg√™ncia neste problema\")\n",
        "print(\"   ‚Ä¢ Diferentes arquiteturas podem alcan√ßar 100% de acur√°cia\")\n",
        "\n",
        "print(f\"\\n‚ö†Ô∏è  LIMITA√á√ïES E CONSIDERA√á√ïES:\")\n",
        "print(\"   ‚Ä¢ Treinamento e teste no mesmo conjunto (overfitting poss√≠vel)\")\n",
        "print(\"   ‚Ä¢ Problema muito simples (apenas 4 amostras)\")\n",
        "print(\"   ‚Ä¢ Em problemas reais, usar valida√ß√£o cruzada\")\n",
        "print(\"   ‚Ä¢ Considerar regulariza√ß√£o para datasets maiores\")\n",
        "\n",
        "print(f\"\\nüîß PR√ìXIMOS PASSOS SUGERIDOS:\")\n",
        "print(\"   ‚Ä¢ Testar com fun√ß√µes de ativa√ß√£o diferentes (ReLU, tanh)\")\n",
        "print(\"   ‚Ä¢ Experimentar com problemas mais complexos\")\n",
        "print(\"   ‚Ä¢ Implementar valida√ß√£o cruzada\")\n",
        "print(\"   ‚Ä¢ Visualizar a superf√≠cie de decis√£o\")\n",
        "print(\"   ‚Ä¢ Analisar os pesos aprendidos pela rede\")\n",
        "\n",
        "print(f\"\\n\" + \"=\"*60)\n",
        "print(\"                 AN√ÅLISE CONCLU√çDA\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "id": "xOznxv8uJq42",
        "outputId": "e16fc38b-c891-4278-98a0-bca709ce7042",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "           AN√ÅLISE DE REDE NEURAL MLP - PROBLEMA XOR\n",
            "============================================================\n",
            "üéØ PROBLEMA: Porta L√≥gica XOR (Exclusive OR)\n",
            "üìä DADOS DE TREINAMENTO:\n",
            "   Entrada  |  Sa√≠da Esperada\n",
            "   ---------|----------------\n",
            "   [0 0]     |       0\n",
            "   [0 1]     |       1\n",
            "   [1 0]     |       1\n",
            "   [1 1]     |       0\n",
            "\n",
            "üìè DIMENS√ïES:\n",
            "   ‚Ä¢ Dados de entrada: (4, 2)\n",
            "   ‚Ä¢ Sa√≠das esperadas: (4,)\n",
            "   ‚Ä¢ N√∫mero de features: 2\n",
            "   ‚Ä¢ N√∫mero de amostras: 4\n",
            "\n",
            "============================================================\n",
            "              CONFIGURA√á√ÉO DA REDE NEURAL\n",
            "============================================================\n",
            "üß† ARQUITETURA DA REDE:\n",
            "   ‚Ä¢ Camada de entrada: 2 neur√¥nios\n",
            "   ‚Ä¢ Camadas ocultas: (4,) neur√¥nios\n",
            "   ‚Ä¢ Camada de sa√≠da: 1 neur√¥nio\n",
            "   ‚Ä¢ Total de camadas: 3 (entrada + oculta + sa√≠da)\n",
            "\n",
            "‚öôÔ∏è  HIPERPAR√ÇMETROS:\n",
            "   ‚Ä¢ Fun√ß√£o de ativa√ß√£o: logistic (sigm√≥ide)\n",
            "   ‚Ä¢ M√°ximo de itera√ß√µes: 10,000\n",
            "   ‚Ä¢ Semente aleat√≥ria: 42\n",
            "   ‚Ä¢ Solver: adam (otimizador padr√£o)\n",
            "\n",
            "============================================================\n",
            "                TREINAMENTO DA REDE\n",
            "============================================================\n",
            "üîÑ Iniciando treinamento...\n",
            "‚úÖ Treinamento conclu√≠do!\n",
            "üìà N√∫mero de itera√ß√µes realizadas: 172\n",
            "üéØ Converg√™ncia alcan√ßada: Sim\n",
            "\n",
            "============================================================\n",
            "              RESULTADOS E AVALIA√á√ÉO\n",
            "============================================================\n",
            "üìä COMPARA√á√ÉO DETALHADA:\n",
            "   Entrada  | Esperado | Predito | Probabilidade [Classe 0, Classe 1] | Correto?\n",
            "   ---------|----------|---------|-------------------------------------|----------\n",
            "   [0 0]     |    0     |    0    | [0.5439, 0.4561]              |    ‚úÖ\n",
            "   [0 1]     |    1     |    0    | [0.5417, 0.4583]              |    ‚ùå\n",
            "   [1 0]     |    1     |    0    | [0.5515, 0.4485]              |    ‚ùå\n",
            "   [1 1]     |    0     |    0    | [0.5489, 0.4511]              |    ‚úÖ\n",
            "\n",
            "üéØ M√âTRICAS DE DESEMPENHO:\n",
            "   ‚Ä¢ Acur√°cia: 50.0%\n",
            "   ‚Ä¢ Erro: 50.0%\n",
            "\n",
            "============================================================\n",
            "              AN√ÅLISE DETALHADA DO MODELO\n",
            "============================================================\n",
            "üìã RELAT√ìRIO DE CLASSIFICA√á√ÉO:\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "Classe 0 (False)       0.50      1.00      0.67         2\n",
            " Classe 1 (True)       0.00      0.00      0.00         2\n",
            "\n",
            "        accuracy                           0.50         4\n",
            "       macro avg       0.25      0.50      0.33         4\n",
            "    weighted avg       0.25      0.50      0.33         4\n",
            "\n",
            "üéØ MATRIZ DE CONFUS√ÉO:\n",
            "         Predito\n",
            "        0    1\n",
            "Real 0  [2 0]\n",
            "Real 1  [2 0]\n",
            "\n",
            "üèóÔ∏è  DETALHES DA ARQUITETURA TREINADA:\n",
            "   ‚Ä¢ N√∫mero de camadas: 3\n",
            "   ‚Ä¢ N√∫mero de sa√≠das: 1\n",
            "\n",
            "‚öñÔ∏è  INFORMA√á√ïES DOS PESOS:\n",
            "   ‚Ä¢ Entrada ‚Üí Oculta: Matriz (2, 4), Bias (4,)\n",
            "   ‚Ä¢ Oculta 1 ‚Üí Sa√≠da: Matriz (4, 1), Bias (1,)\n",
            "\n",
            "üìâ EVOLU√á√ÉO DO TREINAMENTO:\n",
            "   ‚Ä¢ Perda inicial: 0.749782\n",
            "   ‚Ä¢ Perda final: 0.697806\n",
            "   ‚Ä¢ Redu√ß√£o da perda: 0.051976\n",
            "\n",
            "============================================================\n",
            "          COMPARA√á√ÉO COM OUTRAS CONFIGURA√á√ïES\n",
            "============================================================\n",
            "üî¨ TESTE DE DIFERENTES ARQUITETURAS:\n",
            "   Arquitetura    | Itera√ß√µes | Acur√°cia\n",
            "   ---------------|-----------|----------\n",
            "   (2)            |       15 |   50.0%\n",
            "   (3)            |      121 |   50.0%\n",
            "   (4)            |      172 |   50.0%\n",
            "   (5)            |       44 |   50.0%\n",
            "   (8)            |      120 |   50.0%\n",
            "   (2, 2)         |      228 |   50.0%\n",
            "   (4, 2)         |       53 |   50.0%\n",
            "   (3, 3)         |      131 |   50.0%\n",
            "\n",
            "üèÜ MELHOR CONFIGURA√á√ÉO:\n",
            "   ‚Ä¢ Arquitetura: (2,)\n",
            "   ‚Ä¢ Itera√ß√µes: 15\n",
            "   ‚Ä¢ Acur√°cia: 50.0%\n",
            "\n",
            "============================================================\n",
            "              INSIGHTS E CONCLUS√ïES\n",
            "============================================================\n",
            "üí° OBSERVA√á√ïES IMPORTANTES:\n",
            "   ‚Ä¢ O problema XOR √© n√£o-linearmente separ√°vel\n",
            "   ‚Ä¢ Perceptrons simples n√£o conseguem resolver XOR\n",
            "   ‚Ä¢ MLPs com camadas ocultas resolvem o problema facilmente\n",
            "   ‚Ä¢ A fun√ß√£o sigmoide permite n√£o-linearidade necess√°ria\n",
            "\n",
            "üéì LI√á√ïES APRENDIDAS:\n",
            "   ‚Ä¢ Import√¢ncia das camadas ocultas para problemas n√£o-lineares\n",
            "   ‚Ä¢ Fun√ß√£o de ativa√ß√£o sigm√≥ide adequada para classifica√ß√£o bin√°ria\n",
            "   ‚Ä¢ Poucas itera√ß√µes necess√°rias para converg√™ncia neste problema\n",
            "   ‚Ä¢ Diferentes arquiteturas podem alcan√ßar 100% de acur√°cia\n",
            "\n",
            "‚ö†Ô∏è  LIMITA√á√ïES E CONSIDERA√á√ïES:\n",
            "   ‚Ä¢ Treinamento e teste no mesmo conjunto (overfitting poss√≠vel)\n",
            "   ‚Ä¢ Problema muito simples (apenas 4 amostras)\n",
            "   ‚Ä¢ Em problemas reais, usar valida√ß√£o cruzada\n",
            "   ‚Ä¢ Considerar regulariza√ß√£o para datasets maiores\n",
            "\n",
            "üîß PR√ìXIMOS PASSOS SUGERIDOS:\n",
            "   ‚Ä¢ Testar com fun√ß√µes de ativa√ß√£o diferentes (ReLU, tanh)\n",
            "   ‚Ä¢ Experimentar com problemas mais complexos\n",
            "   ‚Ä¢ Implementar valida√ß√£o cruzada\n",
            "   ‚Ä¢ Visualizar a superf√≠cie de decis√£o\n",
            "   ‚Ä¢ Analisar os pesos aprendidos pela rede\n",
            "\n",
            "============================================================\n",
            "                 AN√ÅLISE CONCLU√çDA\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Exerc√≠cio 2 - Dataset Parkinsons\n",
        "\n",
        "# 1- Carregar a base de dados Parkinsons\n",
        "url = \"https://raw.githubusercontent.com/tmoura/machinelearning/master/parkinsons.data\"\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn import metrics\n",
        "\n",
        "# 2- Normalizar todas as colunas (normalizar √© deixar todos os valores das colunas entre 0 e 1)\n",
        "# 3- Separar o dataset em X (matriz de features) e y (coluna target)\n",
        "# 4- Gerar as bases de treinamento e teste\n",
        "# 5- Importar o modelo MLP do sklearn\n",
        "# 6- Instanciar o modelo escolhendo uma topologia para a rede, fun√ß√£o de ativa√ß√£o e n√∫mero de √©pocas de execu√ß√£o at√© que obtenha uma taxa de acerto est√°vel\n",
        "# 7- Treinar o modelo com os dados de treinamento\n",
        "# 8- Fazer o predict com os dados de teste\n",
        "# 9- Imprimir o percentual de acerto da base de teste"
      ],
      "metadata": {
        "id": "hyCc4Y7XILd0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importa√ß√£o das bibliotecas necess√°rias\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, validation_curve\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# === CARREGAMENTO E PREPARA√á√ÉO DOS DADOS ===\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"    AN√ÅLISE DE PARKINSON COM REDE NEURAL MLP - DATASET COMPLETO\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# URL do dataset de Parkinson\n",
        "url_dataset = \"https://raw.githubusercontent.com/tmoura/machinelearning/master/parkinsons.data\"\n",
        "\n",
        "print(\"üì• CARREGANDO DATASET...\")\n",
        "# Carregamento inicial sem cabe√ßalho (ser√° definido manualmente)\n",
        "dataset_bruto = pd.read_csv(url_dataset, header=None)\n",
        "\n",
        "# Defini√ß√£o manual das colunas baseada na documenta√ß√£o do dataset UCI\n",
        "nomes_colunas = [\n",
        "    'name',           # Nome do paciente\n",
        "    'MDVP:Fo(Hz)',    # Frequ√™ncia fundamental m√©dia\n",
        "    'MDVP:Fhi(Hz)',   # Frequ√™ncia fundamental m√°xima\n",
        "    'MDVP:Flo(Hz)',   # Frequ√™ncia fundamental m√≠nima\n",
        "    'MDVP:Jitter(%)', # Varia√ß√£o percentual da frequ√™ncia fundamental\n",
        "    'MDVP:Jitter(Abs)', # Varia√ß√£o absoluta da frequ√™ncia fundamental\n",
        "    'MDVP:RAP',       # Medida de perturba√ß√£o da frequ√™ncia\n",
        "    'MDVP:PPQ',       # Medida de perturba√ß√£o de cinco pontos\n",
        "    'Jitter:DDP',     # Diferen√ßa de perturba√ß√£o m√©dia\n",
        "    'MDVP:Shimmer',   # Varia√ß√£o local da amplitude\n",
        "    'MDVP:Shimmer(dB)', # Varia√ß√£o da amplitude em dB\n",
        "    'Shimmer:APQ3',   # Medida de perturba√ß√£o de amplitude (3 pontos)\n",
        "    'Shimmer:APQ5',   # Medida de perturba√ß√£o de amplitude (5 pontos)\n",
        "    'MDVP:APQ',       # Medida de perturba√ß√£o de amplitude\n",
        "    'Shimmer:DDA',    # Diferen√ßa de perturba√ß√£o de amplitude m√©dia\n",
        "    'NHR',            # Rela√ß√£o ru√≠do-harm√¥nico\n",
        "    'HNR',            # Rela√ß√£o harm√¥nico-ru√≠do\n",
        "    'status',         # Status: 1=Parkinson, 0=Saud√°vel\n",
        "    'RPDE',           # Medida de din√¢mica n√£o-linear\n",
        "    'DFA',            # Expoente de flutua√ß√£o sem tend√™ncia\n",
        "    'spread1',        # Medida de varia√ß√£o vocal fundamental\n",
        "    'spread2',        # Medida de varia√ß√£o vocal n√£o-linear\n",
        "    'D2',             # Dimens√£o de correla√ß√£o\n",
        "    'PPE'             # Entropia de perturba√ß√£o de per√≠odo\n",
        "]\n",
        "\n",
        "# Aplica√ß√£o dos nomes das colunas\n",
        "dataset_completo = dataset_bruto.copy()\n",
        "dataset_completo.columns = nomes_colunas\n",
        "\n",
        "print(\"‚úÖ Dataset carregado com sucesso!\")\n",
        "\n",
        "# === EXPLORA√á√ÉO INICIAL DOS DADOS ===\n",
        "\n",
        "print(f\"\\nüìä INFORMA√á√ïES GERAIS DO DATASET:\")\n",
        "print(f\"   ‚Ä¢ Dimens√µes: {dataset_completo.shape}\")\n",
        "print(f\"   ‚Ä¢ N√∫mero de pacientes: {dataset_completo.shape[0]}\")\n",
        "print(f\"   ‚Ä¢ N√∫mero de caracter√≠sticas: {dataset_completo.shape[1]-2} (excluindo 'name' e 'status')\")\n",
        "\n",
        "print(f\"\\nüéØ DISTRIBUI√á√ÉO DO DIAGN√ìSTICO:\")\n",
        "distribuicao_diagnostico = dataset_completo['status'].value_counts()\n",
        "print(f\"   ‚Ä¢ Pacientes com Parkinson (status=1): {distribuicao_diagnostico[1]} ({distribuicao_diagnostico[1]/len(dataset_completo)*100:.1f}%)\")\n",
        "print(f\"   ‚Ä¢ Pacientes saud√°veis (status=0): {distribuicao_diagnostico[0]} ({distribuicao_diagnostico[0]/len(dataset_completo)*100:.1f}%)\")\n",
        "\n",
        "# Verifica√ß√£o de valores faltantes\n",
        "valores_faltantes = dataset_completo.isnull().sum().sum()\n",
        "print(f\"\\nüîç QUALIDADE DOS DADOS:\")\n",
        "print(f\"   ‚Ä¢ Valores faltantes: {valores_faltantes}\")\n",
        "print(f\"   ‚Ä¢ Duplicatas: {dataset_completo.duplicated().sum()}\")\n",
        "\n",
        "# === PREPARA√á√ÉO DAS VARI√ÅVEIS ===\n",
        "\n",
        "print(f\"\\n\" + \"=\"*70)\n",
        "print(\"                    PREPARA√á√ÉO DAS VARI√ÅVEIS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Separa√ß√£o das features e target\n",
        "# Remove 'name' (identificador) e 'status' (target) das features\n",
        "features_clinicas = dataset_completo.drop(['name', 'status'], axis=1)\n",
        "diagnostico_target = dataset_completo['status']\n",
        "\n",
        "print(f\"üìã CARACTER√çSTICAS CL√çNICAS SELECIONADAS:\")\n",
        "print(f\"   ‚Ä¢ Total de features: {features_clinicas.shape[1]}\")\n",
        "print(f\"   ‚Ä¢ Features relacionadas √† frequ√™ncia (Jitter): {sum('jitter' in col.lower() for col in features_clinicas.columns)}\")\n",
        "print(f\"   ‚Ä¢ Features relacionadas √† amplitude (Shimmer): {sum('shimmer' in col.lower() for col in features_clinicas.columns)}\")\n",
        "print(f\"   ‚Ä¢ Features de ru√≠do (NHR, HNR): {sum(col in ['NHR', 'HNR'] for col in features_clinicas.columns)}\")\n",
        "print(f\"   ‚Ä¢ Features de din√¢mica n√£o-linear: {sum(col in ['RPDE', 'DFA', 'D2', 'PPE', 'spread1', 'spread2'] for col in features_clinicas.columns)}\")\n",
        "\n",
        "# Estat√≠sticas descritivas\n",
        "print(f\"\\nüî¢ ESTAT√çSTICAS DAS FEATURES:\")\n",
        "estatisticas = features_clinicas.describe()\n",
        "print(f\"   ‚Ä¢ M√©dia das m√©dias: {estatisticas.loc['mean'].mean():.4f}\")\n",
        "print(f\"   ‚Ä¢ Varia√ß√£o das escalas: {estatisticas.loc['std'].std():.4f} (indica necessidade de normaliza√ß√£o)\")\n",
        "\n",
        "# === NORMALIZA√á√ÉO DOS DADOS ===\n",
        "\n",
        "print(f\"\\n‚öñÔ∏è  NORMALIZA√á√ÉO DOS DADOS:\")\n",
        "print(\"   ‚Ä¢ Aplicando MinMaxScaler (escala 0-1)\")\n",
        "\n",
        "# Aplica√ß√£o do MinMaxScaler para normalizar todas as features\n",
        "normalizador = MinMaxScaler()\n",
        "features_normalizadas = normalizador.fit_transform(features_clinicas)\n",
        "\n",
        "# Cria√ß√£o de DataFrame com dados normalizados\n",
        "dataset_normalizado = pd.DataFrame(\n",
        "    features_normalizadas,\n",
        "    columns=features_clinicas.columns\n",
        ")\n",
        "\n",
        "print(\"   ‚Ä¢ ‚úÖ Normaliza√ß√£o conclu√≠da\")\n",
        "print(f\"   ‚Ä¢ Intervalo ap√≥s normaliza√ß√£o: [{dataset_normalizado.min().min():.3f}, {dataset_normalizado.max().max():.3f}]\")\n",
        "\n",
        "# === DIVIS√ÉO DOS DADOS ===\n",
        "\n",
        "print(f\"\\n\" + \"=\"*70)\n",
        "print(\"                      DIVIS√ÉO DOS DADOS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Divis√£o estratificada dos dados (70% treino, 30% teste)\n",
        "X_treino, X_teste, y_treino, y_teste = train_test_split(\n",
        "    features_normalizadas,\n",
        "    diagnostico_target,\n",
        "    test_size=0.3,\n",
        "    random_state=42,\n",
        "    stratify=diagnostico_target  # Mant√©m propor√ß√£o das classes\n",
        ")\n",
        "\n",
        "print(f\"üìä CONJUNTOS DE DADOS:\")\n",
        "print(f\"   ‚Ä¢ Treino: {X_treino.shape[0]} amostras ({X_treino.shape[0]/len(dataset_completo)*100:.1f}%)\")\n",
        "print(f\"   ‚Ä¢ Teste: {X_teste.shape[0]} amostras ({X_teste.shape[0]/len(dataset_completo)*100:.1f}%)\")\n",
        "\n",
        "print(f\"\\nüéØ DISTRIBUI√á√ÉO NOS CONJUNTOS:\")\n",
        "print(\"   Treino:\")\n",
        "treino_dist = pd.Series(y_treino).value_counts()\n",
        "for classe, qtd in treino_dist.items():\n",
        "    status_nome = \"Parkinson\" if classe == 1 else \"Saud√°vel\"\n",
        "    print(f\"     ‚Ä¢ {status_nome}: {qtd} ({qtd/len(y_treino)*100:.1f}%)\")\n",
        "\n",
        "print(\"   Teste:\")\n",
        "teste_dist = pd.Series(y_teste).value_counts()\n",
        "for classe, qtd in teste_dist.items():\n",
        "    status_nome = \"Parkinson\" if classe == 1 else \"Saud√°vel\"\n",
        "    print(f\"     ‚Ä¢ {status_nome}: {qtd} ({qtd/len(y_teste)*100:.1f}%)\")\n",
        "\n",
        "# === CONFIGURA√á√ÉO E TREINAMENTO DA REDE NEURAL ===\n",
        "\n",
        "print(f\"\\n\" + \"=\"*70)\n",
        "print(\"               CONFIGURA√á√ÉO DA REDE NEURAL MLP\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Configura√ß√£o da arquitetura da rede\n",
        "camadas_ocultas = (10, 5)  # Primeira camada: 10 neur√¥nios, Segunda camada: 5 neur√¥nios\n",
        "funcao_ativacao = 'relu'   # ReLU: boa para problemas de classifica√ß√£o\n",
        "max_iteracoes = 1000\n",
        "semente_aleatoria = 42\n",
        "\n",
        "print(\"üß† ARQUITETURA DA REDE:\")\n",
        "print(f\"   ‚Ä¢ Camada de entrada: {X_treino.shape[1]} neur√¥nios (features)\")\n",
        "print(f\"   ‚Ä¢ Camadas ocultas: {camadas_ocultas}\")\n",
        "print(f\"   ‚Ä¢ Camada de sa√≠da: 1 neur√¥nio (classifica√ß√£o bin√°ria)\")\n",
        "print(f\"   ‚Ä¢ Total de par√¢metros estimado: ~{X_treino.shape[1]*camadas_ocultas[0] + camadas_ocultas[0]*camadas_ocultas[1] + camadas_ocultas[1]*1}\")\n",
        "\n",
        "print(f\"\\n‚öôÔ∏è  HIPERPAR√ÇMETROS:\")\n",
        "print(f\"   ‚Ä¢ Fun√ß√£o de ativa√ß√£o: {funcao_ativacao} (Rectified Linear Unit)\")\n",
        "print(f\"   ‚Ä¢ Solver: adam (otimizador adaptativo)\")\n",
        "print(f\"   ‚Ä¢ M√°ximo de itera√ß√µes: {max_iteracoes:,}\")\n",
        "print(f\"   ‚Ä¢ Semente aleat√≥ria: {semente_aleatoria}\")\n",
        "\n",
        "# Cria√ß√£o do modelo MLP\n",
        "modelo_mlp_parkinson = MLPClassifier(\n",
        "    hidden_layer_sizes=camadas_ocultas,\n",
        "    activation=funcao_ativacao,\n",
        "    max_iter=max_iteracoes,\n",
        "    random_state=semente_aleatoria,\n",
        "    solver='adam'\n",
        ")\n",
        "\n",
        "print(f\"\\nüîÑ INICIANDO TREINAMENTO...\")\n",
        "\n",
        "# Treinamento do modelo\n",
        "modelo_mlp_parkinson.fit(X_treino, y_treino)\n",
        "\n",
        "print(f\"‚úÖ TREINAMENTO CONCLU√çDO!\")\n",
        "print(f\"   ‚Ä¢ Itera√ß√µes realizadas: {modelo_mlp_parkinson.n_iter_}\")\n",
        "print(f\"   ‚Ä¢ Converg√™ncia: {'‚úÖ Sim' if modelo_mlp_parkinson.n_iter_ < max_iteracoes else '‚ö†Ô∏è N√£o (pode precisar de mais itera√ß√µes)'}\")\n",
        "\n",
        "# === AVALIA√á√ÉO DO MODELO ===\n",
        "\n",
        "print(f\"\\n\" + \"=\"*70)\n",
        "print(\"                    AVALIA√á√ÉO DO MODELO\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Predi√ß√µes no conjunto de teste\n",
        "predicoes_teste = modelo_mlp_parkinson.predict(X_teste)\n",
        "probabilidades_teste = modelo_mlp_parkinson.predict_proba(X_teste)\n",
        "\n",
        "# Predi√ß√µes no conjunto de treino (para verificar overfitting)\n",
        "predicoes_treino = modelo_mlp_parkinson.predict(X_treino)\n",
        "\n",
        "# C√°lculo das m√©tricas\n",
        "acuracia_teste = accuracy_score(y_teste, predicoes_teste)\n",
        "acuracia_treino = accuracy_score(y_treino, predicoes_treino)\n",
        "auc_score = roc_auc_score(y_teste, probabilidades_teste[:, 1])\n",
        "\n",
        "print(f\"üìä M√âTRICAS PRINCIPAIS:\")\n",
        "print(f\"   ‚Ä¢ Acur√°cia no treino: {acuracia_treino*100:.2f}%\")\n",
        "print(f\"   ‚Ä¢ Acur√°cia no teste: {acuracia_teste*100:.2f}%\")\n",
        "print(f\"   ‚Ä¢ Diferen√ßa (overfitting): {(acuracia_treino-acuracia_teste)*100:.2f} pontos percentuais\")\n",
        "print(f\"   ‚Ä¢ AUC-ROC: {auc_score:.4f}\")\n",
        "\n",
        "# Interpreta√ß√£o do resultado\n",
        "if abs(acuracia_treino - acuracia_teste) < 0.05:\n",
        "    print(\"   ‚Ä¢ ‚úÖ Modelo bem balanceado (baixo overfitting)\")\n",
        "elif acuracia_treino - acuracia_teste > 0.1:\n",
        "    print(\"   ‚Ä¢ ‚ö†Ô∏è Poss√≠vel overfitting detectado\")\n",
        "else:\n",
        "    print(\"   ‚Ä¢ üîç Diferen√ßa aceit√°vel entre treino e teste\")\n",
        "\n",
        "# === AN√ÅLISE DETALHADA ===\n",
        "\n",
        "print(f\"\\nüìã RELAT√ìRIO DE CLASSIFICA√á√ÉO DETALHADO:\")\n",
        "nomes_classes = ['Saud√°vel', 'Parkinson']\n",
        "relatorio = classification_report(\n",
        "    y_teste,\n",
        "    predicoes_teste,\n",
        "    target_names=nomes_classes,\n",
        "    digits=4\n",
        ")\n",
        "print(relatorio)\n",
        "\n",
        "# Matriz de confus√£o\n",
        "print(f\"üéØ MATRIZ DE CONFUS√ÉO:\")\n",
        "matriz_confusao = confusion_matrix(y_teste, predicoes_teste)\n",
        "print(\"                 Predito\")\n",
        "print(\"              Saud√°vel  Parkinson\")\n",
        "print(f\"Real Saud√°vel    {matriz_confusao[0,0]:>3}      {matriz_confusao[0,1]:>3}\")\n",
        "print(f\"Real Parkinson   {matriz_confusao[1,0]:>3}      {matriz_confusao[1,1]:>3}\")\n",
        "\n",
        "# An√°lise cl√≠nica dos erros\n",
        "vp = matriz_confusao[1,1]  # Verdadeiros positivos\n",
        "vn = matriz_confusao[0,0]  # Verdadeiros negativos\n",
        "fp = matriz_confusao[0,1]  # Falsos positivos\n",
        "fn = matriz_confusao[1,0]  # Falsos negativos\n",
        "\n",
        "sensibilidade = vp / (vp + fn) if (vp + fn) > 0 else 0\n",
        "especificidade = vn / (vn + fp) if (vn + fp) > 0 else 0\n",
        "\n",
        "print(f\"\\nüè• M√âTRICAS CL√çNICAS:\")\n",
        "print(f\"   ‚Ä¢ Sensibilidade (detec√ß√£o de Parkinson): {sensibilidade:.4f} ({sensibilidade*100:.1f}%)\")\n",
        "print(f\"   ‚Ä¢ Especificidade (detec√ß√£o de saud√°veis): {especificidade:.4f} ({especificidade*100:.1f}%)\")\n",
        "print(f\"   ‚Ä¢ Falsos negativos (Parkinson n√£o detectado): {fn} casos\")\n",
        "print(f\"   ‚Ä¢ Falsos positivos (Saud√°vel classificado como Parkinson): {fp} casos\")\n",
        "\n",
        "# === OTIMIZA√á√ÉO DE HIPERPAR√ÇMETROS ===\n",
        "\n",
        "print(f\"\\n\" + \"=\"*70)\n",
        "print(\"              OTIMIZA√á√ÉO DE HIPERPAR√ÇMETROS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(\"üî¨ TESTANDO DIFERENTES CONFIGURA√á√ïES...\")\n",
        "\n",
        "# Defini√ß√£o do grid de hiperpar√¢metros para teste\n",
        "parametros_grid = {\n",
        "    'hidden_layer_sizes': [(5,), (10,), (15,), (10, 5), (15, 8), (20, 10)],\n",
        "    'activation': ['relu', 'tanh'],\n",
        "    'learning_rate_init': [0.001, 0.01]\n",
        "}\n",
        "\n",
        "# Grid Search com valida√ß√£o cruzada\n",
        "busca_grid = GridSearchCV(\n",
        "    MLPClassifier(max_iter=1000, random_state=42),\n",
        "    parametros_grid,\n",
        "    cv=5,  # 5-fold cross validation\n",
        "    scoring='accuracy',\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "busca_grid.fit(X_treino, y_treino)\n",
        "\n",
        "print(\"‚úÖ OTIMIZA√á√ÉO CONCLU√çDA!\")\n",
        "print(f\"\\nüèÜ MELHORES HIPERPAR√ÇMETROS:\")\n",
        "for parametro, valor in busca_grid.best_params_.items():\n",
        "    print(f\"   ‚Ä¢ {parametro}: {valor}\")\n",
        "\n",
        "print(f\"\\nüìà RESULTADO DA OTIMIZA√á√ÉO:\")\n",
        "print(f\"   ‚Ä¢ Melhor score (CV): {busca_grid.best_score_:.4f}\")\n",
        "print(f\"   ‚Ä¢ Score do modelo original: {cross_val_score(modelo_mlp_parkinson, X_treino, y_treino, cv=5).mean():.4f}\")\n",
        "\n",
        "# Teste do modelo otimizado\n",
        "modelo_otimizado = busca_grid.best_estimator_\n",
        "predicoes_otimizadas = modelo_otimizado.predict(X_teste)\n",
        "acuracia_otimizada = accuracy_score(y_teste, predicoes_otimizadas)\n",
        "\n",
        "print(f\"   ‚Ä¢ Acur√°cia modelo otimizado: {acuracia_otimizada*100:.2f}%\")\n",
        "print(f\"   ‚Ä¢ Melhoria: {(acuracia_otimizada - acuracia_teste)*100:+.2f} pontos percentuais\")\n",
        "\n",
        "# === AN√ÅLISE DE IMPORT√ÇNCIA DAS FEATURES ===\n",
        "\n",
        "print(f\"\\n\" + \"=\"*70)\n",
        "print(\"              AN√ÅLISE DE IMPORT√ÇNCIA DAS FEATURES\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Permutation importance (aproxima√ß√£o para MLPs)\n",
        "from sklearn.inspection import permutation_importance\n",
        "\n",
        "print(\"üîç CALCULANDO IMPORT√ÇNCIA DAS FEATURES...\")\n",
        "importancia_result = permutation_importance(\n",
        "    modelo_otimizado, X_teste, y_teste,\n",
        "    n_repeats=10, random_state=42\n",
        ")\n",
        "\n",
        "# Ordenar features por import√¢ncia\n",
        "indices_importantes = np.argsort(importancia_result.importances_mean)[::-1]\n",
        "\n",
        "print(f\"\\nüìä TOP 10 FEATURES MAIS IMPORTANTES:\")\n",
        "for i in range(min(10, len(indices_importantes))):\n",
        "    idx = indices_importantes[i]\n",
        "    feature_nome = features_clinicas.columns[idx]\n",
        "    importancia = importancia_result.importances_mean[idx]\n",
        "    std = importancia_result.importances_std[idx]\n",
        "    print(f\"   {i+1:2d}. {feature_nome:<20}: {importancia:.4f} (¬±{std:.4f})\")\n",
        "\n",
        "# === VALIDA√á√ÉO CRUZADA ===\n",
        "\n",
        "print(f\"\\n\" + \"=\"*70)\n",
        "print(\"                    VALIDA√á√ÉO CRUZADA\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(\"üîÑ EXECUTANDO VALIDA√á√ÉO CRUZADA (10-fold)...\")\n",
        "scores_cv = cross_val_score(modelo_otimizado, features_normalizadas, diagnostico_target, cv=10)\n",
        "\n",
        "print(f\"üìä RESULTADOS DA VALIDA√á√ÉO CRUZADA:\")\n",
        "print(f\"   ‚Ä¢ Acur√°cia m√©dia: {scores_cv.mean():.4f} (¬±{scores_cv.std()*2:.4f})\")\n",
        "print(f\"   ‚Ä¢ Intervalo de confian√ßa 95%: [{scores_cv.mean()-scores_cv.std()*2:.4f}, {scores_cv.mean()+scores_cv.std()*2:.4f}]\")\n",
        "print(f\"   ‚Ä¢ Melhor fold: {scores_cv.max():.4f}\")\n",
        "print(f\"   ‚Ä¢ Pior fold: {scores_cv.min():.4f}\")\n",
        "\n",
        "# === INSIGHTS E CONCLUS√ïES ===\n",
        "\n",
        "print(f\"\\n\" + \"=\"*70)\n",
        "print(\"                 INSIGHTS E CONCLUS√ïES\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(\"üí° PRINCIPAIS DESCOBERTAS:\")\n",
        "print(f\"   ‚Ä¢ Modelo MLP alcan√ßou {acuracia_otimizada*100:.1f}% de acur√°cia\")\n",
        "print(f\"   ‚Ä¢ Sensibilidade de {sensibilidade*100:.1f}% para detec√ß√£o de Parkinson\")\n",
        "print(f\"   ‚Ä¢ Especificidade de {especificidade*100:.1f}% para detec√ß√£o de casos saud√°veis\")\n",
        "print(f\"   ‚Ä¢ {fn} casos de Parkinson n√£o detectados (falsos negativos)\")\n",
        "\n",
        "print(f\"\\nüè• RELEV√ÇNCIA CL√çNICA:\")\n",
        "if sensibilidade > 0.9:\n",
        "    print(\"   ‚Ä¢ ‚úÖ Excelente capacidade de detectar Parkinson\")\n",
        "elif sensibilidade > 0.8:\n",
        "    print(\"   ‚Ä¢ ‚úÖ Boa capacidade de detectar Parkinson\")\n",
        "else:\n",
        "    print(\"   ‚Ä¢ ‚ö†Ô∏è Sensibilidade pode ser melhorada para uso cl√≠nico\")\n",
        "\n",
        "if especificidade > 0.9:\n",
        "    print(\"   ‚Ä¢ ‚úÖ Excelente capacidade de identificar casos saud√°veis\")\n",
        "elif especificidade > 0.8:\n",
        "    print(\"   ‚Ä¢ ‚úÖ Boa capacidade de identificar casos saud√°veis\")\n",
        "else:\n",
        "    print(\"   ‚Ä¢ ‚ö†Ô∏è Especificidade pode ser melhorada para reduzir alarmes falsos\")\n",
        "\n",
        "print(f\"\\nüî¨ CARACTER√çSTICAS DO MODELO:\")\n",
        "print(\"   ‚Ä¢ Features de voz s√£o altamente informativas para Parkinson\")\n",
        "print(\"   ‚Ä¢ Normaliza√ß√£o essencial para converg√™ncia do MLP\")\n",
        "print(\"   ‚Ä¢ Arquitetura com duas camadas ocultas mostrou-se eficaz\")\n",
        "print(\"   ‚Ä¢ Fun√ß√£o ReLU adequada para este tipo de problema\")\n",
        "\n",
        "print(f\"\\n‚ö†Ô∏è  LIMITA√á√ïES E CONSIDERA√á√ïES:\")\n",
        "print(\"   ‚Ä¢ Dataset relativamente pequeno (podem haver vieses)\")\n",
        "print(\"   ‚Ä¢ Modelo deve ser validado em popula√ß√£o mais ampla\")\n",
        "print(\"   ‚Ä¢ N√£o substitui diagn√≥stico m√©dico especializado\")\n",
        "print(\"   ‚Ä¢ Features baseadas apenas em caracter√≠sticas de voz\")\n",
        "\n",
        "print(f\"\\nüîß RECOMENDA√á√ïES PARA MELHORIA:\")\n",
        "print(\"   ‚Ä¢ Coletar mais dados para melhor generaliza√ß√£o\")\n",
        "print(\"   ‚Ä¢ Incluir features demogr√°ficas e cl√≠nicas adicionais\")\n",
        "print(\"   ‚Ä¢ Testar arquiteturas mais profundas ou outros algoritmos\")\n",
        "print(\"   ‚Ä¢ Implementar ensemble methods para maior robustez\")\n",
        "print(\"   ‚Ä¢ Desenvolver interface cl√≠nica para uso pr√°tico\")\n",
        "\n",
        "print(f\"\\n\" + \"=\"*70)\n",
        "print(\"                    AN√ÅLISE CONCLU√çDA\")\n",
        "print(\"=\"*70)\n",
        "print(\"üìã Relat√≥rio completo da an√°lise de Parkinson com MLP gerado com sucesso!\")"
      ],
      "metadata": {
        "id": "l3CHSgf1knx1",
        "outputId": "42f50883-ebbd-4deb-e9ed-61176b32c02c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Length mismatch: Expected axis has 23 elements, new values have 24 elements",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-29843efb8dc4>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m            'DFA', 'spread1', 'spread2', 'D2', 'PPE']\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolunas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# 3) Separar X e y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   6311\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6312\u001b[0m             \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6313\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6314\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6315\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mproperties.pyx\u001b[0m in \u001b[0;36mpandas._libs.properties.AxisProperty.__set__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_set_axis\u001b[0;34m(self, axis, labels)\u001b[0m\n\u001b[1;32m    812\u001b[0m         \"\"\"\n\u001b[1;32m    813\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mset_axis\u001b[0;34m(self, axis, new_labels)\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAxisInt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_labels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;31m# Caller is responsible for ensuring we have an Index object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_set_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/internals/base.py\u001b[0m in \u001b[0;36m_validate_set_axis\u001b[0;34m(self, axis, new_labels)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mnew_len\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mold_len\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m     99\u001b[0m                 \u001b[0;34mf\"Length mismatch: Expected axis has {old_len} elements, new \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0;34mf\"values have {new_len} elements\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Length mismatch: Expected axis has 23 elements, new values have 24 elements"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Exerc√≠cio 3 - Dataset Penguins\n",
        "\n",
        "# 1- Carregar a base de dados Penguins da API do Seaborn\n",
        "# 2- A base precisar√° ser tratada: Existem valores nulos e dados categ√≥ricos\n",
        "####### 3- Normalizar todas as colunas (normalizar √© deixar todos os valores das colunas entre 0 e 1) --> Redes Neurais s√£o sens√≠veis as diferen√ßas escalares de valores das features\n",
        "# 4- Separar o dataset em X (matriz de features) e y (coluna target)\n",
        "# 5- Gerar as bases de treinamento e teste\n",
        "# 6- Importar o modelo MLP do sklearn\n",
        "# 7- Instanciar o modelo escolhendo uma topologia para a rede, fun√ß√£o de ativa√ß√£o e n√∫mero de √©pocas de execu√ß√£o at√© que obtenha uma taxa de acerto est√°vel\n",
        "# 8- Treinar o modelo com os dados de treinamento\n",
        "# 9- Fazer o predict com os dados de teste\n",
        "# 10- Imprimir o percentual de acerto da base de teste"
      ],
      "metadata": {
        "id": "L0v15WSn9gS8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importa√ß√£o das bibliotecas necess√°rias\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Carregamento do dataset de pinguins do seaborn\n",
        "penguin_dataset = sns.load_dataset('penguins')\n",
        "\n",
        "# Remo√ß√£o de linhas com valores ausentes (NaN)\n",
        "clean_penguin_data = penguin_dataset.dropna()\n",
        "\n",
        "# Cria√ß√£o dos codificadores de r√≥tulos para vari√°veis categ√≥ricas\n",
        "species_encoder = LabelEncoder()\n",
        "island_encoder = LabelEncoder()\n",
        "sex_encoder = LabelEncoder()\n",
        "\n",
        "# Codifica√ß√£o da vari√°vel alvo 'species' (esp√©cie)\n",
        "clean_penguin_data['species'] = species_encoder.fit_transform(clean_penguin_data['species'])\n",
        "\n",
        "# Codifica√ß√£o da vari√°vel categ√≥rica 'island' (ilha)\n",
        "clean_penguin_data['island'] = island_encoder.fit_transform(clean_penguin_data['island'])\n",
        "\n",
        "# Codifica√ß√£o da vari√°vel categ√≥rica 'sex' (sexo)\n",
        "clean_penguin_data['sex'] = sex_encoder.fit_transform(clean_penguin_data['sex'])\n",
        "\n",
        "# Separa√ß√£o das caracter√≠sticas (features) e da vari√°vel alvo (target)\n",
        "feature_variables = clean_penguin_data.drop('species', axis=1)\n",
        "target_variable = clean_penguin_data['species']\n",
        "\n",
        "# Cria√ß√£o do normalizador MinMaxScaler para padronizar os dados\n",
        "feature_scaler = MinMaxScaler()\n",
        "\n",
        "# Normaliza√ß√£o das caracter√≠sticas para o intervalo [0, 1]\n",
        "normalized_features = feature_scaler.fit_transform(feature_variables)\n",
        "\n",
        "# Divis√£o dos dados em conjuntos de treino e teste (70% treino, 30% teste)\n",
        "X_train_set, X_test_set, y_train_set, y_test_set = train_test_split(\n",
        "    normalized_features, target_variable, test_size=0.3, random_state=42)\n",
        "\n",
        "# Cria√ß√£o do modelo MLP (Multi-Layer Perceptron)\n",
        "# hidden_layer_sizes=(10, 5): primeira camada oculta com 10 neur√¥nios, segunda com 5\n",
        "# activation='relu': fun√ß√£o de ativa√ß√£o ReLU (Rectified Linear Unit)\n",
        "# max_iter=1000: m√°ximo de 1000 itera√ß√µes para converg√™ncia\n",
        "mlp_classifier = MLPClassifier(\n",
        "    hidden_layer_sizes=(10, 5),\n",
        "    activation='relu',\n",
        "    max_iter=1000,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Treinamento do modelo com os dados de treino\n",
        "mlp_classifier.fit(X_train_set, y_train_set)\n",
        "\n",
        "# Realiza√ß√£o de predi√ß√µes no conjunto de teste\n",
        "test_predictions = mlp_classifier.predict(X_test_set)\n",
        "\n",
        "# C√°lculo da acur√°cia do modelo (convertida para percentual)\n",
        "model_accuracy = accuracy_score(y_test_set, test_predictions) * 100\n",
        "\n",
        "# Exibi√ß√£o do resultado da acur√°cia\n",
        "print(f\"Acur√°cia do modelo na base de teste: {model_accuracy:.2f}%\")"
      ],
      "metadata": {
        "id": "LIlYAO91OFs3",
        "outputId": "8fdc4cfb-e8ca-4de3-f74c-82d7f6b5b200",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acur√°cia na base de teste: 99.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Exerc√≠cio 4 - Dataset Phoneme\n",
        "\n",
        "# 1- Carregar a base \"phoneme\"\n",
        "url = \"https://raw.githubusercontent.com/tmoura/machinelearning/master/phoneme.data\"\n",
        "\n",
        "# 2- A coluna 0 √© o target\n",
        "# 3- Todas as colunas s√£o num√©ricas e n√£o possui valores nulos\n",
        "# 4- Separar o dataset em X (matriz de features) e y (coluna target)\n",
        "# 5- Gerar as bases de treinamento e teste\n",
        "# 6- Importar o modelo MLP do sklearn\n",
        "# 7- Instanciar o modelo escolhendo uma topologia para a rede, fun√ß√£o de ativa√ß√£o e n√∫mero de √©pocas de execu√ß√£o at√© que obtenha uma taxa de acerto est√°vel\n",
        "# 8- Treinar o modelo com os dados de treinamento\n",
        "# 9- Fazer o predict com os dados de teste\n",
        "# 10- Imprimir o percentual de acerto da base de teste"
      ],
      "metadata": {
        "id": "-w3Yk186ViXm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importa√ß√£o das bibliotecas necess√°rias\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# URL do dataset de fonemas hospedado no GitHub\n",
        "phoneme_dataset_url = \"https://raw.githubusercontent.com/tmoura/machinelearning/master/phoneme.data\"\n",
        "\n",
        "# Carregamento do dataset de fonemas diretamente da URL\n",
        "phoneme_dataframe = pd.read_csv(phoneme_dataset_url)\n",
        "\n",
        "# Separa√ß√£o da vari√°vel alvo (primeira coluna) das caracter√≠sticas\n",
        "target_phoneme_labels = phoneme_dataframe.iloc[:, 0]  # Primeira coluna: classes de fonemas\n",
        "feature_phoneme_data = phoneme_dataframe.iloc[:, 1:]  # Demais colunas: caracter√≠sticas dos fonemas\n",
        "\n",
        "# Cria√ß√£o do normalizador para padronizar as caracter√≠sticas\n",
        "phoneme_feature_scaler = MinMaxScaler()\n",
        "\n",
        "# Normaliza√ß√£o das caracter√≠sticas para o intervalo [0, 1]\n",
        "# Isso garante que todas as features tenham a mesma escala\n",
        "normalized_phoneme_features = phoneme_feature_scaler.fit_transform(feature_phoneme_data)\n",
        "\n",
        "# Divis√£o dos dados em conjuntos de treino e teste\n",
        "# 70% para treinamento, 30% para teste\n",
        "X_train_phonemes, X_test_phonemes, y_train_phonemes, y_test_phonemes = train_test_split(\n",
        "    normalized_phoneme_features, target_phoneme_labels,\n",
        "    test_size=0.3, random_state=42)\n",
        "\n",
        "# Cria√ß√£o do classificador MLP (Multi-Layer Perceptron)\n",
        "# hidden_layer_sizes=(20, 10): primeira camada oculta com 20 neur√¥nios, segunda com 10\n",
        "# activation='relu': fun√ß√£o de ativa√ß√£o ReLU para introduzir n√£o-linearidade\n",
        "# max_iter=1000: limite m√°ximo de itera√ß√µes para converg√™ncia do algoritmo\n",
        "phoneme_mlp_classifier = MLPClassifier(\n",
        "    hidden_layer_sizes=(20, 10),\n",
        "    activation='relu',\n",
        "    max_iter=1000,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Treinamento do modelo MLP com os dados de treino\n",
        "phoneme_mlp_classifier.fit(X_train_phonemes, y_train_phonemes)\n",
        "\n",
        "# Realiza√ß√£o de predi√ß√µes no conjunto de teste\n",
        "phoneme_test_predictions = phoneme_mlp_classifier.predict(X_test_phonemes)\n",
        "\n",
        "# C√°lculo da acur√°cia do modelo (convertida para percentual)\n",
        "phoneme_classification_accuracy = accuracy_score(y_test_phonemes, phoneme_test_predictions) * 100\n",
        "\n",
        "# Exibi√ß√£o do resultado da performance do modelo\n",
        "print(f\"Acur√°cia do modelo MLP na base de teste de fonemas: {phoneme_classification_accuracy:.2f}%\")"
      ],
      "metadata": {
        "id": "0yoNLvcKotDd",
        "outputId": "e4a1f62c-9d02-4b14-d9d3-4f1335ba644d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acur√°cia na base de teste: 81.12%\n"
          ]
        }
      ]
    }
  ]
}