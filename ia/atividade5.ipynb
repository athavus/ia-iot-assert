{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_3zNAo4jbCKF"
      },
      "outputs": [],
      "source": [
        "## Exerc√≠cio 1 - Dataset \"car_crashes\" do seaborn\n",
        "\n",
        "# 1) Carregar o dataset \"car_crashes\"do seaborn\n",
        "# 2) Dropar a coluna \"abbrev\"\n",
        "# 3) Separar o dataframe, deixando a coluna 'total' para o target (coluna objetivo - y) e o restante para o X\n",
        "# 4) Normalizar todo o X\n",
        "\n",
        "# df = X.values\n",
        "# min_max_scaler = preprocessing.MinMaxScaler()\n",
        "# x_scaled = min_max_scaler.fit_transform(df)\n",
        "# X = pd.DataFrame(x_scaled)\n",
        "\n",
        "# 5) Separar os dados em treinamento e teste\n",
        "# 6) Treinar um modelo linear\n",
        "# 7) Treinar uma √°rvores de regress√£o\n",
        "# 8) Treinar um KNN para regress√£o\n",
        "# 9) Apresentar os resultados dos erros usando: MSE, MAE e RMSE para os 3 modelos"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importa√ß√£o das bibliotecas necess√°rias\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import numpy as np\n",
        "\n",
        "# Carregamento do dataset de acidentes de carro do Seaborn\n",
        "dataset_acidentes = sns.load_dataset('car_crashes')\n",
        "\n",
        "# Remove a coluna 'abbrev' (abrevia√ß√£o dos estados) pois n√£o √© √∫til para a predi√ß√£o\n",
        "dataset_limpo = dataset_acidentes.drop(columns=['abbrev'])\n",
        "\n",
        "# Separa√ß√£o das vari√°veis dependente (target) e independentes (features)\n",
        "variavel_target = dataset_limpo['total']  # Total de acidentes (vari√°vel a ser predita)\n",
        "variaveis_independentes = dataset_limpo.drop(columns=['total'])  # Todas as outras colunas\n",
        "\n",
        "# Normaliza√ß√£o dos dados usando MinMaxScaler\n",
        "# Transforma os valores para uma escala entre 0 e 1, melhorando o desempenho dos algoritmos\n",
        "valores_originais = variaveis_independentes.values\n",
        "normalizador = preprocessing.MinMaxScaler()\n",
        "dados_normalizados = normalizador.fit_transform(valores_originais)\n",
        "\n",
        "# Cria√ß√£o de um DataFrame com os dados normalizados, mantendo os nomes das colunas originais\n",
        "features_normalizadas = pd.DataFrame(dados_normalizados, columns=variaveis_independentes.columns)\n",
        "\n",
        "# Divis√£o dos dados em conjuntos de treino (80%) e teste (20%)\n",
        "# random_state=42 garante reprodutibilidade dos resultados\n",
        "X_treino, X_teste, y_treino, y_teste = train_test_split(\n",
        "    features_normalizadas,\n",
        "    variavel_target,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# === TREINAMENTO DOS MODELOS ===\n",
        "\n",
        "# 1. Modelo de Regress√£o Linear\n",
        "modelo_regressao_linear = LinearRegression()\n",
        "modelo_regressao_linear.fit(X_treino, y_treino)\n",
        "\n",
        "# 2. Modelo de √Årvore de Decis√£o\n",
        "modelo_arvore_decisao = DecisionTreeRegressor(random_state=42)\n",
        "modelo_arvore_decisao.fit(X_treino, y_treino)\n",
        "\n",
        "# 3. Modelo K-Nearest Neighbors (KNN)\n",
        "modelo_knn = KNeighborsRegressor()\n",
        "modelo_knn.fit(X_treino, y_treino)\n",
        "\n",
        "# === PREDI√á√ïES NOS DADOS DE TESTE ===\n",
        "\n",
        "predicoes_regressao_linear = modelo_regressao_linear.predict(X_teste)\n",
        "predicoes_arvore_decisao = modelo_arvore_decisao.predict(X_teste)\n",
        "predicoes_knn = modelo_knn.predict(X_teste)\n",
        "\n",
        "# === FUN√á√ÉO PARA CALCULAR M√âTRICAS DE ERRO ===\n",
        "\n",
        "def calcular_metricas_erro(valores_reais, valores_preditos):\n",
        "    \"\"\"\n",
        "    Calcula tr√™s m√©tricas de erro para avaliar a performance do modelo:\n",
        "    - MSE (Mean Squared Error): Erro quadr√°tico m√©dio\n",
        "    - MAE (Mean Absolute Error): Erro absoluto m√©dio\n",
        "    - RMSE (Root Mean Squared Error): Raiz do erro quadr√°tico m√©dio\n",
        "    \"\"\"\n",
        "    mse = mean_squared_error(valores_reais, valores_preditos)\n",
        "    mae = mean_absolute_error(valores_reais, valores_preditos)\n",
        "    rmse = np.sqrt(mse)\n",
        "    return mse, mae, rmse\n",
        "\n",
        "# === AVALIA√á√ÉO DOS MODELOS ===\n",
        "\n",
        "# C√°lculo das m√©tricas de erro para cada modelo\n",
        "metricas_regressao_linear = calcular_metricas_erro(y_teste, predicoes_regressao_linear)\n",
        "metricas_arvore_decisao = calcular_metricas_erro(y_teste, predicoes_arvore_decisao)\n",
        "metricas_knn = calcular_metricas_erro(y_teste, predicoes_knn)\n",
        "\n",
        "# Exibi√ß√£o dos resultados\n",
        "print(\"=== RESULTADOS DOS MODELOS ===\")\n",
        "print(\"\\n1. Regress√£o Linear:\")\n",
        "print(f\"   MSE: {metricas_regressao_linear[0]:.4f}\")\n",
        "print(f\"   MAE: {metricas_regressao_linear[1]:.4f}\")\n",
        "print(f\"   RMSE: {metricas_regressao_linear[2]:.4f}\")\n",
        "\n",
        "print(\"\\n2. √Årvore de Decis√£o:\")\n",
        "print(f\"   MSE: {metricas_arvore_decisao[0]:.4f}\")\n",
        "print(f\"   MAE: {metricas_arvore_decisao[1]:.4f}\")\n",
        "print(f\"   RMSE: {metricas_arvore_decisao[2]:.4f}\")\n",
        "\n",
        "print(\"\\n3. K-Nearest Neighbors:\")\n",
        "print(f\"   MSE: {metricas_knn[0]:.4f}\")\n",
        "print(f\"   MAE: {metricas_knn[1]:.4f}\")\n",
        "print(f\"   RMSE: {metricas_knn[2]:.4f}\")"
      ],
      "metadata": {
        "id": "mdF3TK-hvIze",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a48ecb37-e0ad-402d-d0f1-e523a05ef404"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== RESULTADOS DOS MODELOS ===\n",
            "\n",
            "1. Regress√£o Linear:\n",
            "   MSE: 2.1862\n",
            "   MAE: 1.0921\n",
            "   RMSE: 1.4786\n",
            "\n",
            "2. √Årvore de Decis√£o:\n",
            "   MSE: 3.4755\n",
            "   MAE: 1.5364\n",
            "   RMSE: 1.8643\n",
            "\n",
            "3. K-Nearest Neighbors:\n",
            "   MSE: 6.5678\n",
            "   MAE: 1.9909\n",
            "   RMSE: 2.5628\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Exerc√≠cio 2 - Dataset Parkinsons (dataset com 2 classes)\n",
        "\n",
        "# 1) Carregar o dataset \"parkinsons\" pela URL abaixo:\n",
        "\n",
        "# url = \"https://raw.githubusercontent.com/tmoura/machinelearning/master/parkinsons.data\"\n",
        "\n",
        "# 2) Separar os dados y e X. A coluna y √© a coluna 0 (zero)\n",
        "# 3) Normalizar todas as colunas de X (usando o mesmo c√≥digo da quest√£o anterior)\n",
        "# 4) Separar oa dados em treinamento e teste\n",
        "# 5) Treinar um modelo de regress√£o log√≠stica\n",
        "# 6) Treinar uma √°rvore de decis√£o\n",
        "# 7) Treinar um KNN para classifica√ß√£o\n",
        "# 8) Apresentar os resultados de acur√°cia em percentual"
      ],
      "metadata": {
        "id": "NecXgZ5iytCc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importa√ß√£o das bibliotecas necess√°rias\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Carregamento dos dados do dataset de Parkinson\n",
        "url_dataset = \"https://raw.githubusercontent.com/tmoura/machinelearning/master/parkinsons.data\"\n",
        "dataset_parkinsons = pd.read_csv(url_dataset)\n",
        "\n",
        "# Visualiza√ß√£o inicial dos dados\n",
        "print(\"=== INFORMA√á√ïES DO DATASET ===\")\n",
        "print(f\"Dimens√µes do dataset: {dataset_parkinsons.shape}\")\n",
        "print(f\"\\nPrimeiras 5 linhas:\")\n",
        "print(dataset_parkinsons.head())\n",
        "print(f\"\\nColunas dispon√≠veis:\")\n",
        "print(dataset_parkinsons.columns.tolist())\n",
        "\n",
        "# Separa√ß√£o das vari√°veis dependente (target) e independente (feature)\n",
        "# Assumindo que a primeira coluna √© o target (status de Parkinson: 0=saud√°vel, 1=Parkinson)\n",
        "variavel_target = dataset_parkinsons.iloc[:, 0]  # Primeira coluna (diagn√≥stico)\n",
        "feature_selecionada = dataset_parkinsons.iloc[:, [1]]  # Segunda coluna como feature √∫nica\n",
        "\n",
        "print(f\"\\nVari√°vel target: {dataset_parkinsons.columns[0]}\")\n",
        "print(f\"Feature selecionada: {dataset_parkinsons.columns[1]}\")\n",
        "print(f\"Distribui√ß√£o do target:\")\n",
        "print(variavel_target.value_counts())\n",
        "\n",
        "# Normaliza√ß√£o dos dados usando MinMaxScaler\n",
        "# Transforma os valores para uma escala entre 0 e 1, importante para algoritmos sens√≠veis √† escala\n",
        "normalizador = preprocessing.MinMaxScaler()\n",
        "feature_normalizada = normalizador.fit_transform(feature_selecionada)\n",
        "\n",
        "# Cria√ß√£o de um DataFrame com os dados normalizados, mantendo o nome da coluna original\n",
        "features_normalizadas = pd.DataFrame(feature_normalizada, columns=feature_selecionada.columns)\n",
        "\n",
        "# Divis√£o dos dados em conjuntos de treino (70%) e teste (30%)\n",
        "# random_state=42 garante reprodutibilidade dos resultados\n",
        "X_treino, X_teste, y_treino, y_teste = train_test_split(\n",
        "    features_normalizadas,\n",
        "    variavel_target,\n",
        "    test_size=0.3,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(f\"\\n=== DIVIS√ÉO DOS DADOS ===\")\n",
        "print(f\"Dados de treino: {X_treino.shape[0]} amostras\")\n",
        "print(f\"Dados de teste: {X_teste.shape[0]} amostras\")\n",
        "\n",
        "# === TREINAMENTO DOS MODELOS DE CLASSIFICA√á√ÉO ===\n",
        "\n",
        "# 1. Modelo de Regress√£o Log√≠stica\n",
        "# Algoritmo linear que usa fun√ß√£o log√≠stica para classifica√ß√£o bin√°ria\n",
        "modelo_regressao_logistica = LogisticRegression(random_state=42)\n",
        "modelo_regressao_logistica.fit(X_treino, y_treino)\n",
        "\n",
        "# 2. Modelo de √Årvore de Decis√£o\n",
        "# Algoritmo baseado em regras que cria uma √°rvore de decis√µes\n",
        "modelo_arvore_decisao = DecisionTreeClassifier(random_state=42)\n",
        "modelo_arvore_decisao.fit(X_treino, y_treino)\n",
        "\n",
        "# 3. Modelo K-Nearest Neighbors (KNN)\n",
        "# Algoritmo que classifica baseado na classe dos k vizinhos mais pr√≥ximos\n",
        "modelo_knn = KNeighborsClassifier(n_neighbors=5)  # Usando 5 vizinhos como padr√£o\n",
        "modelo_knn.fit(X_treino, y_treino)\n",
        "\n",
        "# === PREDI√á√ïES NOS DADOS DE TESTE ===\n",
        "\n",
        "predicoes_regressao_logistica = modelo_regressao_logistica.predict(X_teste)\n",
        "predicoes_arvore_decisao = modelo_arvore_decisao.predict(X_teste)\n",
        "predicoes_knn = modelo_knn.predict(X_teste)\n",
        "\n",
        "# === AVALIA√á√ÉO DOS MODELOS ===\n",
        "\n",
        "# C√°lculo da acur√°cia para cada modelo\n",
        "acuracia_regressao_logistica = accuracy_score(y_teste, predicoes_regressao_logistica)\n",
        "acuracia_arvore_decisao = accuracy_score(y_teste, predicoes_arvore_decisao)\n",
        "acuracia_knn = accuracy_score(y_teste, predicoes_knn)\n",
        "\n",
        "# === EXIBI√á√ÉO DOS RESULTADOS ===\n",
        "\n",
        "print(\"\\n=== RESULTADOS DOS MODELOS ===\")\n",
        "print(f\"Acur√°cia Regress√£o Log√≠stica: {acuracia_regressao_logistica:.2%}\")\n",
        "print(f\"Acur√°cia √Årvore de Decis√£o: {acuracia_arvore_decisao:.2%}\")\n",
        "print(f\"Acur√°cia KNN: {acuracia_knn:.2%}\")\n",
        "\n",
        "# Identifica√ß√£o do melhor modelo\n",
        "modelos_resultados = {\n",
        "    'Regress√£o Log√≠stica': acuracia_regressao_logistica,\n",
        "    '√Årvore de Decis√£o': acuracia_arvore_decisao,\n",
        "    'KNN': acuracia_knn\n",
        "}\n",
        "\n",
        "melhor_modelo = max(modelos_resultados, key=modelos_resultados.get)\n",
        "melhor_acuracia = modelos_resultados[melhor_modelo]\n",
        "\n",
        "print(f\"\\nüèÜ Melhor modelo: {melhor_modelo} com {melhor_acuracia:.2%} de acur√°cia\")\n",
        "\n",
        "# === AN√ÅLISE DETALHADA DO MELHOR MODELO ===\n",
        "\n",
        "print(f\"\\n=== AN√ÅLISE DETALHADA - {melhor_modelo.upper()} ===\")\n",
        "\n",
        "# Seleciona as predi√ß√µes do melhor modelo\n",
        "if melhor_modelo == 'Regress√£o Log√≠stica':\n",
        "    melhores_predicoes = predicoes_regressao_logistica\n",
        "elif melhor_modelo == '√Årvore de Decis√£o':\n",
        "    melhores_predicoes = predicoes_arvore_decisao\n",
        "else:\n",
        "    melhores_predicoes = predicoes_knn\n",
        "\n",
        "# Relat√≥rio de classifica√ß√£o detalhado\n",
        "print(\"\\nRelat√≥rio de Classifica√ß√£o:\")\n",
        "print(classification_report(y_teste, melhores_predicoes))\n",
        "\n",
        "# Matriz de confus√£o\n",
        "print(\"\\nMatriz de Confus√£o:\")\n",
        "print(confusion_matrix(y_teste, melhores_predicoes))\n",
        "\n",
        "# === OBSERVA√á√ïES IMPORTANTES ===\n",
        "print(\"\\n=== OBSERVA√á√ïES ===\")\n",
        "print(\"‚ö†Ô∏è  Este modelo usa apenas UMA feature para classifica√ß√£o.\")\n",
        "print(\"üí° Para melhor desempenho, considere usar m√∫ltiplas features relevantes.\")\n",
        "print(\"üìä A normaliza√ß√£o MinMaxScaler √© especialmente importante para KNN.\")\n",
        "print(\"üî¨ Para diagn√≥stico m√©dico, considere m√©tricas al√©m da acur√°cia (sensibilidade, especificidade).\")"
      ],
      "metadata": {
        "id": "bMimnrL22gL9",
        "outputId": "2b5cc0d8-3324-48e1-da3a-a23d596818fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acur√°cia Regress√£o Log√≠stica: 0.85%\n",
            "Acur√°cia √Årvore de Decis√£o: 0.71%\n",
            "Acur√°cia KNN: 0.78%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Exerc√≠cio 3 - Dataset attention do seaborn\n",
        "\n",
        "# 1) Carregar o dataset \"attention\" do seaborn\n",
        "# 2) Fazer um LabelEncoder na coluna \"attention\"\n",
        "# 3) Separar o dataframe, deixando a coluna 'attention' para o target (coluna objetivo - y) e as colunas \"solutions\" e \"score\" para o X\n",
        "# 4) Normalizar todo o X usando o mesmo c√≥digo da quest√£o 1\n",
        "# 5) Separar os dados em treinamento e teste\n",
        "# 6) Treinar um modelo de regress√£o log√≠stica\n",
        "# 7) Treinar uma √°rvore de decis√£o\n",
        "# 8) Treinar um KNN para classifica√ß√£o\n",
        "# 9) Apresentar os resultados de acur√°rica em percentual"
      ],
      "metadata": {
        "id": "1PAlFH5Au-11"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importa√ß√£o das bibliotecas necess√°rias\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "import numpy as np\n",
        "\n",
        "# Carregamento do dataset de aten√ß√£o do Seaborn\n",
        "dataset_atencao = sns.load_dataset('attention')\n",
        "\n",
        "# Verifica√ß√£o inicial dos dados\n",
        "print(\"=== INFORMA√á√ïES INICIAIS DO DATASET ===\")\n",
        "print(f\"Dimens√µes do dataset: {dataset_atencao.shape}\")\n",
        "print(f\"\\nPrimeiras 5 linhas:\")\n",
        "print(dataset_atencao.head())\n",
        "print(f\"\\nInforma√ß√µes sobre as colunas:\")\n",
        "print(dataset_atencao.info())\n",
        "print(f\"\\nEstat√≠sticas descritivas:\")\n",
        "print(dataset_atencao.describe())\n",
        "\n",
        "# Verifica√ß√£o da distribui√ß√£o da vari√°vel target antes da codifica√ß√£o\n",
        "print(f\"\\nDistribui√ß√£o original da vari√°vel 'attention':\")\n",
        "print(dataset_atencao['attention'].value_counts())\n",
        "\n",
        "# === PREPARA√á√ÉO DOS DADOS ===\n",
        "\n",
        "# Codifica√ß√£o da vari√°vel categ√≥rica 'attention' para valores num√©ricos\n",
        "# LabelEncoder converte categorias em n√∫meros (ex: 'high' -> 1, 'low' -> 0)\n",
        "codificador_target = LabelEncoder()\n",
        "dataset_codificado = dataset_atencao.copy()\n",
        "dataset_codificado['attention'] = codificador_target.fit_transform(dataset_atencao['attention'])\n",
        "\n",
        "# Mostra o mapeamento das categorias\n",
        "print(f\"\\nMapeamento das categorias ap√≥s codifica√ß√£o:\")\n",
        "categorias_originais = codificador_target.classes_\n",
        "for i, categoria in enumerate(categorias_originais):\n",
        "    print(f\"  {categoria} -> {i}\")\n",
        "\n",
        "print(f\"\\nDistribui√ß√£o ap√≥s codifica√ß√£o:\")\n",
        "print(dataset_codificado['attention'].value_counts().sort_index())\n",
        "\n",
        "# Separa√ß√£o das vari√°veis independentes (features) e dependente (target)\n",
        "variavel_target = dataset_codificado['attention']  # Vari√°vel a ser predita\n",
        "features_selecionadas = dataset_codificado[['solutions', 'score']]  # Features para predi√ß√£o\n",
        "\n",
        "print(f\"\\n=== INFORMA√á√ïES DAS VARI√ÅVEIS ===\")\n",
        "print(f\"Target: 'attention' (n√≠veis de aten√ß√£o)\")\n",
        "print(f\"Features: {list(features_selecionadas.columns)} (solu√ß√µes e pontua√ß√£o)\")\n",
        "print(f\"Formato das features: {features_selecionadas.shape}\")\n",
        "print(f\"Formato do target: {variavel_target.shape}\")\n",
        "\n",
        "# Normaliza√ß√£o das features usando MinMaxScaler\n",
        "# Transforma os valores para escala 0-1, importante para algoritmos sens√≠veis √† escala (especialmente KNN)\n",
        "normalizador = MinMaxScaler()\n",
        "features_normalizadas_array = normalizador.fit_transform(features_selecionadas)\n",
        "\n",
        "# Cria√ß√£o de DataFrame com dados normalizados, preservando nomes das colunas\n",
        "features_normalizadas = pd.DataFrame(\n",
        "    features_normalizadas_array,\n",
        "    columns=features_selecionadas.columns\n",
        ")\n",
        "\n",
        "print(f\"\\n=== NORMALIZA√á√ÉO DOS DADOS ===\")\n",
        "print(\"Estat√≠sticas antes da normaliza√ß√£o:\")\n",
        "print(features_selecionadas.describe())\n",
        "print(\"\\nEstat√≠sticas ap√≥s normaliza√ß√£o:\")\n",
        "print(features_normalizadas.describe())\n",
        "\n",
        "# Divis√£o dos dados em conjuntos de treino (70%) e teste (30%)\n",
        "# random_state=42 garante reprodutibilidade dos resultados\n",
        "X_treino, X_teste, y_treino, y_teste = train_test_split(\n",
        "    features_normalizadas,\n",
        "    variavel_target,\n",
        "    test_size=0.3,\n",
        "    random_state=42,\n",
        "    stratify=variavel_target  # Mant√©m propor√ß√£o das classes nos conjuntos\n",
        ")\n",
        "\n",
        "print(f\"\\n=== DIVIS√ÉO DOS DADOS ===\")\n",
        "print(f\"Dados de treino: {X_treino.shape[0]} amostras\")\n",
        "print(f\"Dados de teste: {X_teste.shape[0]} amostras\")\n",
        "print(f\"Distribui√ß√£o no treino:\")\n",
        "print(y_treino.value_counts().sort_index())\n",
        "print(f\"Distribui√ß√£o no teste:\")\n",
        "print(y_teste.value_counts().sort_index())\n",
        "\n",
        "# === TREINAMENTO DOS MODELOS DE CLASSIFICA√á√ÉO ===\n",
        "\n",
        "print(\"\\n=== TREINAMENTO DOS MODELOS ===\")\n",
        "\n",
        "# 1. Modelo de Regress√£o Log√≠stica\n",
        "# Algoritmo linear que usa fun√ß√£o log√≠stica para classifica√ß√£o\n",
        "modelo_regressao_logistica = LogisticRegression(random_state=42, max_iter=1000)\n",
        "modelo_regressao_logistica.fit(X_treino, y_treino)\n",
        "print(\"‚úì Regress√£o Log√≠stica treinada\")\n",
        "\n",
        "# 2. Modelo de √Årvore de Decis√£o\n",
        "# Algoritmo baseado em regras que cria uma estrutura de √°rvore\n",
        "modelo_arvore_decisao = DecisionTreeClassifier(random_state=42)\n",
        "modelo_arvore_decisao.fit(X_treino, y_treino)\n",
        "print(\"‚úì √Årvore de Decis√£o treinada\")\n",
        "\n",
        "# 3. Modelo K-Nearest Neighbors (KNN)\n",
        "# Algoritmo que classifica baseado na classe dos k vizinhos mais pr√≥ximos\n",
        "modelo_knn = KNeighborsClassifier(n_neighbors=5)\n",
        "modelo_knn.fit(X_treino, y_treino)\n",
        "print(\"‚úì KNN treinado\")\n",
        "\n",
        "# === PREDI√á√ïES NOS DADOS DE TESTE ===\n",
        "\n",
        "predicoes_regressao_logistica = modelo_regressao_logistica.predict(X_teste)\n",
        "predicoes_arvore_decisao = modelo_arvore_decisao.predict(X_teste)\n",
        "predicoes_knn = modelo_knn.predict(X_teste)\n",
        "\n",
        "# === AVALIA√á√ÉO DOS MODELOS ===\n",
        "\n",
        "# C√°lculo da acur√°cia para cada modelo\n",
        "acuracia_regressao_logistica = accuracy_score(y_teste, predicoes_regressao_logistica)\n",
        "acuracia_arvore_decisao = accuracy_score(y_teste, predicoes_arvore_decisao)\n",
        "acuracia_knn = accuracy_score(y_teste, predicoes_knn)\n",
        "\n",
        "# === EXIBI√á√ÉO DOS RESULTADOS ===\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"           RESULTADOS DOS MODELOS\")\n",
        "print(\"=\"*50)\n",
        "print(f\"ü§ñ Regress√£o Log√≠stica: {acuracia_regressao_logistica*100:.2f}%\")\n",
        "print(f\"üå≥ √Årvore de Decis√£o:   {acuracia_arvore_decisao*100:.2f}%\")\n",
        "print(f\"üë• KNN (k=5):           {acuracia_knn*100:.2f}%\")\n",
        "\n",
        "# Identifica√ß√£o do melhor modelo\n",
        "modelos_resultados = {\n",
        "    'Regress√£o Log√≠stica': acuracia_regressao_logistica,\n",
        "    '√Årvore de Decis√£o': acuracia_arvore_decisao,\n",
        "    'KNN': acuracia_knn\n",
        "}\n",
        "\n",
        "melhor_modelo_nome = max(modelos_resultados, key=modelos_resultados.get)\n",
        "melhor_acuracia = modelos_resultados[melhor_modelo_nome]\n",
        "\n",
        "print(f\"\\nüèÜ MELHOR MODELO: {melhor_modelo_nome}\")\n",
        "print(f\"üìä ACUR√ÅCIA: {melhor_acuracia*100:.2f}%\")\n",
        "\n",
        "# === AN√ÅLISE DETALHADA DO MELHOR MODELO ===\n",
        "\n",
        "print(f\"\\n\" + \"=\"*50)\n",
        "print(f\"      AN√ÅLISE DETALHADA - {melhor_modelo_nome.upper()}\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Seleciona as predi√ß√µes e o modelo do melhor resultado\n",
        "if melhor_modelo_nome == 'Regress√£o Log√≠stica':\n",
        "    melhores_predicoes = predicoes_regressao_logistica\n",
        "    melhor_modelo_obj = modelo_regressao_logistica\n",
        "elif melhor_modelo_nome == '√Årvore de Decis√£o':\n",
        "    melhores_predicoes = predicoes_arvore_decisao\n",
        "    melhor_modelo_obj = modelo_arvore_decisao\n",
        "else:\n",
        "    melhores_predicoes = predicoes_knn\n",
        "    melhor_modelo_obj = modelo_knn\n",
        "\n",
        "# Relat√≥rio de classifica√ß√£o com m√©tricas detalhadas\n",
        "print(\"\\nüìã RELAT√ìRIO DE CLASSIFICA√á√ÉO:\")\n",
        "nomes_classes = [f\"Classe_{i} ({cat})\" for i, cat in enumerate(codificador_target.classes_)]\n",
        "print(classification_report(\n",
        "    y_teste,\n",
        "    melhores_predicoes,\n",
        "    target_names=nomes_classes\n",
        "))\n",
        "\n",
        "# Matriz de confus√£o\n",
        "print(\"\\nüéØ MATRIZ DE CONFUS√ÉO:\")\n",
        "matriz_confusao = confusion_matrix(y_teste, melhores_predicoes)\n",
        "print(\"   Pred:  \", end=\"\")\n",
        "for i in range(len(codificador_target.classes_)):\n",
        "    print(f\"{codificador_target.classes_[i]:>8}\", end=\"\")\n",
        "print()\n",
        "for i, linha in enumerate(matriz_confusao):\n",
        "    print(f\"Real {codificador_target.classes_[i]:>4}: \", end=\"\")\n",
        "    for valor in linha:\n",
        "        print(f\"{valor:>8}\", end=\"\")\n",
        "    print()\n",
        "\n",
        "# An√°lise de import√¢ncia das features (se dispon√≠vel)\n",
        "if hasattr(melhor_modelo_obj, 'feature_importances_'):\n",
        "    print(f\"\\nüìà IMPORT√ÇNCIA DAS FEATURES:\")\n",
        "    importancias = melhor_modelo_obj.feature_importances_\n",
        "    for feature, importancia in zip(features_selecionadas.columns, importancias):\n",
        "        print(f\"  {feature}: {importancia:.4f} ({importancia*100:.1f}%)\")\n",
        "elif hasattr(melhor_modelo_obj, 'coef_'):\n",
        "    print(f\"\\nüìà COEFICIENTES DO MODELO:\")\n",
        "    coeficientes = melhor_modelo_obj.coef_[0]\n",
        "    for feature, coef in zip(features_selecionadas.columns, coeficientes):\n",
        "        print(f\"  {feature}: {coef:.4f}\")\n",
        "\n",
        "# === INSIGHTS E RECOMENDA√á√ïES ===\n",
        "print(f\"\\n\" + \"=\"*50)\n",
        "print(\"           INSIGHTS E RECOMENDA√á√ïES\")\n",
        "print(\"=\"*50)\n",
        "print(\"üí° OBSERVA√á√ïES:\")\n",
        "print(\"  ‚Ä¢ Dataset de aten√ß√£o com features 'solutions' e 'score'\")\n",
        "print(\"  ‚Ä¢ Normaliza√ß√£o MinMaxScaler aplicada (importante para KNN)\")\n",
        "print(\"  ‚Ä¢ Divis√£o estratificada mant√©m propor√ß√£o das classes\")\n",
        "print(\"  ‚Ä¢ LabelEncoder usado para converter categorias em n√∫meros\")\n",
        "\n",
        "print(\"\\nüîß POSS√çVEIS MELHORIAS:\")\n",
        "print(\"  ‚Ä¢ Testar diferentes valores de k para KNN\")\n",
        "print(\"  ‚Ä¢ Aplicar valida√ß√£o cruzada para resultados mais robustos\")\n",
        "print(\"  ‚Ä¢ Considerar feature engineering adicional\")\n",
        "print(\"  ‚Ä¢ Avaliar outras m√©tricas al√©m da acur√°cia\")\n",
        "print(\"  ‚Ä¢ Testar algoritmos ensemble (Random Forest, etc.)\")\n",
        "\n",
        "print(f\"\\n‚ö†Ô∏è  LIMITA√á√ïES:\")\n",
        "print(\"  ‚Ä¢ Apenas 2 features utilizadas\")\n",
        "print(\"  ‚Ä¢ Avalia√ß√£o baseada somente em acur√°cia\")\n",
        "print(\"  ‚Ä¢ Sem otimiza√ß√£o de hiperpar√¢metros\")"
      ],
      "metadata": {
        "id": "ToZSK-uW2g0U",
        "outputId": "7cf33505-5f2f-4ad4-c7bd-407070a8ebbb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X shape: (60, 2)\n",
            "y shape: (60,)\n",
            "Acur√°cia Regress√£o Log√≠stica: 83.33%\n",
            "Acur√°cia √Årvore de Decis√£o: 72.22%\n",
            "Acur√°cia KNN: 61.11%\n"
          ]
        }
      ]
    }
  ]
}