{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_3zNAo4jbCKF"
      },
      "outputs": [],
      "source": [
        "## Exercício 1 - Dataset \"car_crashes\" do seaborn\n",
        "\n",
        "# 1) Carregar o dataset \"car_crashes\"do seaborn\n",
        "# 2) Dropar a coluna \"abbrev\"\n",
        "# 3) Separar o dataframe, deixando a coluna 'total' para o target (coluna objetivo - y) e o restante para o X\n",
        "# 4) Normalizar todo o X\n",
        "\n",
        "# df = X.values\n",
        "# min_max_scaler = preprocessing.MinMaxScaler()\n",
        "# x_scaled = min_max_scaler.fit_transform(df)\n",
        "# X = pd.DataFrame(x_scaled)\n",
        "\n",
        "# 5) Separar os dados em treinamento e teste\n",
        "# 6) Treinar um modelo linear\n",
        "# 7) Treinar uma árvores de regressão\n",
        "# 8) Treinar um KNN para regressão\n",
        "# 9) Apresentar os resultados dos erros usando: MSE, MAE e RMSE para os 3 modelos"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importação das bibliotecas necessárias\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import numpy as np\n",
        "\n",
        "# Carregamento do dataset de acidentes de carro do Seaborn\n",
        "dataset_acidentes = sns.load_dataset('car_crashes')\n",
        "\n",
        "# Remove a coluna 'abbrev' (abreviação dos estados) pois não é útil para a predição\n",
        "dataset_limpo = dataset_acidentes.drop(columns=['abbrev'])\n",
        "\n",
        "# Separação das variáveis dependente (target) e independentes (features)\n",
        "variavel_target = dataset_limpo['total']  # Total de acidentes (variável a ser predita)\n",
        "variaveis_independentes = dataset_limpo.drop(columns=['total'])  # Todas as outras colunas\n",
        "\n",
        "# Normalização dos dados usando MinMaxScaler\n",
        "# Transforma os valores para uma escala entre 0 e 1, melhorando o desempenho dos algoritmos\n",
        "valores_originais = variaveis_independentes.values\n",
        "normalizador = preprocessing.MinMaxScaler()\n",
        "dados_normalizados = normalizador.fit_transform(valores_originais)\n",
        "\n",
        "# Criação de um DataFrame com os dados normalizados, mantendo os nomes das colunas originais\n",
        "features_normalizadas = pd.DataFrame(dados_normalizados, columns=variaveis_independentes.columns)\n",
        "\n",
        "# Divisão dos dados em conjuntos de treino (80%) e teste (20%)\n",
        "# random_state=42 garante reprodutibilidade dos resultados\n",
        "X_treino, X_teste, y_treino, y_teste = train_test_split(\n",
        "    features_normalizadas,\n",
        "    variavel_target,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# === TREINAMENTO DOS MODELOS ===\n",
        "\n",
        "# 1. Modelo de Regressão Linear\n",
        "modelo_regressao_linear = LinearRegression()\n",
        "modelo_regressao_linear.fit(X_treino, y_treino)\n",
        "\n",
        "# 2. Modelo de Árvore de Decisão\n",
        "modelo_arvore_decisao = DecisionTreeRegressor(random_state=42)\n",
        "modelo_arvore_decisao.fit(X_treino, y_treino)\n",
        "\n",
        "# 3. Modelo K-Nearest Neighbors (KNN)\n",
        "modelo_knn = KNeighborsRegressor()\n",
        "modelo_knn.fit(X_treino, y_treino)\n",
        "\n",
        "# === PREDIÇÕES NOS DADOS DE TESTE ===\n",
        "\n",
        "predicoes_regressao_linear = modelo_regressao_linear.predict(X_teste)\n",
        "predicoes_arvore_decisao = modelo_arvore_decisao.predict(X_teste)\n",
        "predicoes_knn = modelo_knn.predict(X_teste)\n",
        "\n",
        "# === FUNÇÃO PARA CALCULAR MÉTRICAS DE ERRO ===\n",
        "\n",
        "def calcular_metricas_erro(valores_reais, valores_preditos):\n",
        "    \"\"\"\n",
        "    Calcula três métricas de erro para avaliar a performance do modelo:\n",
        "    - MSE (Mean Squared Error): Erro quadrático médio\n",
        "    - MAE (Mean Absolute Error): Erro absoluto médio\n",
        "    - RMSE (Root Mean Squared Error): Raiz do erro quadrático médio\n",
        "    \"\"\"\n",
        "    mse = mean_squared_error(valores_reais, valores_preditos)\n",
        "    mae = mean_absolute_error(valores_reais, valores_preditos)\n",
        "    rmse = np.sqrt(mse)\n",
        "    return mse, mae, rmse\n",
        "\n",
        "# === AVALIAÇÃO DOS MODELOS ===\n",
        "\n",
        "# Cálculo das métricas de erro para cada modelo\n",
        "metricas_regressao_linear = calcular_metricas_erro(y_teste, predicoes_regressao_linear)\n",
        "metricas_arvore_decisao = calcular_metricas_erro(y_teste, predicoes_arvore_decisao)\n",
        "metricas_knn = calcular_metricas_erro(y_teste, predicoes_knn)\n",
        "\n",
        "# Exibição dos resultados\n",
        "print(\"=== RESULTADOS DOS MODELOS ===\")\n",
        "print(\"\\n1. Regressão Linear:\")\n",
        "print(f\"   MSE: {metricas_regressao_linear[0]:.4f}\")\n",
        "print(f\"   MAE: {metricas_regressao_linear[1]:.4f}\")\n",
        "print(f\"   RMSE: {metricas_regressao_linear[2]:.4f}\")\n",
        "\n",
        "print(\"\\n2. Árvore de Decisão:\")\n",
        "print(f\"   MSE: {metricas_arvore_decisao[0]:.4f}\")\n",
        "print(f\"   MAE: {metricas_arvore_decisao[1]:.4f}\")\n",
        "print(f\"   RMSE: {metricas_arvore_decisao[2]:.4f}\")\n",
        "\n",
        "print(\"\\n3. K-Nearest Neighbors:\")\n",
        "print(f\"   MSE: {metricas_knn[0]:.4f}\")\n",
        "print(f\"   MAE: {metricas_knn[1]:.4f}\")\n",
        "print(f\"   RMSE: {metricas_knn[2]:.4f}\")"
      ],
      "metadata": {
        "id": "mdF3TK-hvIze",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a48ecb37-e0ad-402d-d0f1-e523a05ef404"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== RESULTADOS DOS MODELOS ===\n",
            "\n",
            "1. Regressão Linear:\n",
            "   MSE: 2.1862\n",
            "   MAE: 1.0921\n",
            "   RMSE: 1.4786\n",
            "\n",
            "2. Árvore de Decisão:\n",
            "   MSE: 3.4755\n",
            "   MAE: 1.5364\n",
            "   RMSE: 1.8643\n",
            "\n",
            "3. K-Nearest Neighbors:\n",
            "   MSE: 6.5678\n",
            "   MAE: 1.9909\n",
            "   RMSE: 2.5628\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Exercício 2 - Dataset Parkinsons (dataset com 2 classes)\n",
        "\n",
        "# 1) Carregar o dataset \"parkinsons\" pela URL abaixo:\n",
        "\n",
        "# url = \"https://raw.githubusercontent.com/tmoura/machinelearning/master/parkinsons.data\"\n",
        "\n",
        "# 2) Separar os dados y e X. A coluna y é a coluna 0 (zero)\n",
        "# 3) Normalizar todas as colunas de X (usando o mesmo código da questão anterior)\n",
        "# 4) Separar oa dados em treinamento e teste\n",
        "# 5) Treinar um modelo de regressão logística\n",
        "# 6) Treinar uma árvore de decisão\n",
        "# 7) Treinar um KNN para classificação\n",
        "# 8) Apresentar os resultados de acurácia em percentual"
      ],
      "metadata": {
        "id": "NecXgZ5iytCc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importação das bibliotecas necessárias\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Carregamento dos dados do dataset de Parkinson\n",
        "url_dataset = \"https://raw.githubusercontent.com/tmoura/machinelearning/master/parkinsons.data\"\n",
        "dataset_parkinsons = pd.read_csv(url_dataset)\n",
        "\n",
        "# Visualização inicial dos dados\n",
        "print(\"=== INFORMAÇÕES DO DATASET ===\")\n",
        "print(f\"Dimensões do dataset: {dataset_parkinsons.shape}\")\n",
        "print(f\"\\nPrimeiras 5 linhas:\")\n",
        "print(dataset_parkinsons.head())\n",
        "print(f\"\\nColunas disponíveis:\")\n",
        "print(dataset_parkinsons.columns.tolist())\n",
        "\n",
        "# Separação das variáveis dependente (target) e independente (feature)\n",
        "# Assumindo que a primeira coluna é o target (status de Parkinson: 0=saudável, 1=Parkinson)\n",
        "variavel_target = dataset_parkinsons.iloc[:, 0]  # Primeira coluna (diagnóstico)\n",
        "feature_selecionada = dataset_parkinsons.iloc[:, [1]]  # Segunda coluna como feature única\n",
        "\n",
        "print(f\"\\nVariável target: {dataset_parkinsons.columns[0]}\")\n",
        "print(f\"Feature selecionada: {dataset_parkinsons.columns[1]}\")\n",
        "print(f\"Distribuição do target:\")\n",
        "print(variavel_target.value_counts())\n",
        "\n",
        "# Normalização dos dados usando MinMaxScaler\n",
        "# Transforma os valores para uma escala entre 0 e 1, importante para algoritmos sensíveis à escala\n",
        "normalizador = preprocessing.MinMaxScaler()\n",
        "feature_normalizada = normalizador.fit_transform(feature_selecionada)\n",
        "\n",
        "# Criação de um DataFrame com os dados normalizados, mantendo o nome da coluna original\n",
        "features_normalizadas = pd.DataFrame(feature_normalizada, columns=feature_selecionada.columns)\n",
        "\n",
        "# Divisão dos dados em conjuntos de treino (70%) e teste (30%)\n",
        "# random_state=42 garante reprodutibilidade dos resultados\n",
        "X_treino, X_teste, y_treino, y_teste = train_test_split(\n",
        "    features_normalizadas,\n",
        "    variavel_target,\n",
        "    test_size=0.3,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(f\"\\n=== DIVISÃO DOS DADOS ===\")\n",
        "print(f\"Dados de treino: {X_treino.shape[0]} amostras\")\n",
        "print(f\"Dados de teste: {X_teste.shape[0]} amostras\")\n",
        "\n",
        "# === TREINAMENTO DOS MODELOS DE CLASSIFICAÇÃO ===\n",
        "\n",
        "# 1. Modelo de Regressão Logística\n",
        "# Algoritmo linear que usa função logística para classificação binária\n",
        "modelo_regressao_logistica = LogisticRegression(random_state=42)\n",
        "modelo_regressao_logistica.fit(X_treino, y_treino)\n",
        "\n",
        "# 2. Modelo de Árvore de Decisão\n",
        "# Algoritmo baseado em regras que cria uma árvore de decisões\n",
        "modelo_arvore_decisao = DecisionTreeClassifier(random_state=42)\n",
        "modelo_arvore_decisao.fit(X_treino, y_treino)\n",
        "\n",
        "# 3. Modelo K-Nearest Neighbors (KNN)\n",
        "# Algoritmo que classifica baseado na classe dos k vizinhos mais próximos\n",
        "modelo_knn = KNeighborsClassifier(n_neighbors=5)  # Usando 5 vizinhos como padrão\n",
        "modelo_knn.fit(X_treino, y_treino)\n",
        "\n",
        "# === PREDIÇÕES NOS DADOS DE TESTE ===\n",
        "\n",
        "predicoes_regressao_logistica = modelo_regressao_logistica.predict(X_teste)\n",
        "predicoes_arvore_decisao = modelo_arvore_decisao.predict(X_teste)\n",
        "predicoes_knn = modelo_knn.predict(X_teste)\n",
        "\n",
        "# === AVALIAÇÃO DOS MODELOS ===\n",
        "\n",
        "# Cálculo da acurácia para cada modelo\n",
        "acuracia_regressao_logistica = accuracy_score(y_teste, predicoes_regressao_logistica)\n",
        "acuracia_arvore_decisao = accuracy_score(y_teste, predicoes_arvore_decisao)\n",
        "acuracia_knn = accuracy_score(y_teste, predicoes_knn)\n",
        "\n",
        "# === EXIBIÇÃO DOS RESULTADOS ===\n",
        "\n",
        "print(\"\\n=== RESULTADOS DOS MODELOS ===\")\n",
        "print(f\"Acurácia Regressão Logística: {acuracia_regressao_logistica:.2%}\")\n",
        "print(f\"Acurácia Árvore de Decisão: {acuracia_arvore_decisao:.2%}\")\n",
        "print(f\"Acurácia KNN: {acuracia_knn:.2%}\")\n",
        "\n",
        "# Identificação do melhor modelo\n",
        "modelos_resultados = {\n",
        "    'Regressão Logística': acuracia_regressao_logistica,\n",
        "    'Árvore de Decisão': acuracia_arvore_decisao,\n",
        "    'KNN': acuracia_knn\n",
        "}\n",
        "\n",
        "melhor_modelo = max(modelos_resultados, key=modelos_resultados.get)\n",
        "melhor_acuracia = modelos_resultados[melhor_modelo]\n",
        "\n",
        "print(f\"\\n🏆 Melhor modelo: {melhor_modelo} com {melhor_acuracia:.2%} de acurácia\")\n",
        "\n",
        "# === ANÁLISE DETALHADA DO MELHOR MODELO ===\n",
        "\n",
        "print(f\"\\n=== ANÁLISE DETALHADA - {melhor_modelo.upper()} ===\")\n",
        "\n",
        "# Seleciona as predições do melhor modelo\n",
        "if melhor_modelo == 'Regressão Logística':\n",
        "    melhores_predicoes = predicoes_regressao_logistica\n",
        "elif melhor_modelo == 'Árvore de Decisão':\n",
        "    melhores_predicoes = predicoes_arvore_decisao\n",
        "else:\n",
        "    melhores_predicoes = predicoes_knn\n",
        "\n",
        "# Relatório de classificação detalhado\n",
        "print(\"\\nRelatório de Classificação:\")\n",
        "print(classification_report(y_teste, melhores_predicoes))\n",
        "\n",
        "# Matriz de confusão\n",
        "print(\"\\nMatriz de Confusão:\")\n",
        "print(confusion_matrix(y_teste, melhores_predicoes))\n",
        "\n",
        "# === OBSERVAÇÕES IMPORTANTES ===\n",
        "print(\"\\n=== OBSERVAÇÕES ===\")\n",
        "print(\"⚠️  Este modelo usa apenas UMA feature para classificação.\")\n",
        "print(\"💡 Para melhor desempenho, considere usar múltiplas features relevantes.\")\n",
        "print(\"📊 A normalização MinMaxScaler é especialmente importante para KNN.\")\n",
        "print(\"🔬 Para diagnóstico médico, considere métricas além da acurácia (sensibilidade, especificidade).\")"
      ],
      "metadata": {
        "id": "bMimnrL22gL9",
        "outputId": "2b5cc0d8-3324-48e1-da3a-a23d596818fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurácia Regressão Logística: 0.85%\n",
            "Acurácia Árvore de Decisão: 0.71%\n",
            "Acurácia KNN: 0.78%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Exercício 3 - Dataset attention do seaborn\n",
        "\n",
        "# 1) Carregar o dataset \"attention\" do seaborn\n",
        "# 2) Fazer um LabelEncoder na coluna \"attention\"\n",
        "# 3) Separar o dataframe, deixando a coluna 'attention' para o target (coluna objetivo - y) e as colunas \"solutions\" e \"score\" para o X\n",
        "# 4) Normalizar todo o X usando o mesmo código da questão 1\n",
        "# 5) Separar os dados em treinamento e teste\n",
        "# 6) Treinar um modelo de regressão logística\n",
        "# 7) Treinar uma árvore de decisão\n",
        "# 8) Treinar um KNN para classificação\n",
        "# 9) Apresentar os resultados de acurárica em percentual"
      ],
      "metadata": {
        "id": "1PAlFH5Au-11"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importação das bibliotecas necessárias\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "import numpy as np\n",
        "\n",
        "# Carregamento do dataset de atenção do Seaborn\n",
        "dataset_atencao = sns.load_dataset('attention')\n",
        "\n",
        "# Verificação inicial dos dados\n",
        "print(\"=== INFORMAÇÕES INICIAIS DO DATASET ===\")\n",
        "print(f\"Dimensões do dataset: {dataset_atencao.shape}\")\n",
        "print(f\"\\nPrimeiras 5 linhas:\")\n",
        "print(dataset_atencao.head())\n",
        "print(f\"\\nInformações sobre as colunas:\")\n",
        "print(dataset_atencao.info())\n",
        "print(f\"\\nEstatísticas descritivas:\")\n",
        "print(dataset_atencao.describe())\n",
        "\n",
        "# Verificação da distribuição da variável target antes da codificação\n",
        "print(f\"\\nDistribuição original da variável 'attention':\")\n",
        "print(dataset_atencao['attention'].value_counts())\n",
        "\n",
        "# === PREPARAÇÃO DOS DADOS ===\n",
        "\n",
        "# Codificação da variável categórica 'attention' para valores numéricos\n",
        "# LabelEncoder converte categorias em números (ex: 'high' -> 1, 'low' -> 0)\n",
        "codificador_target = LabelEncoder()\n",
        "dataset_codificado = dataset_atencao.copy()\n",
        "dataset_codificado['attention'] = codificador_target.fit_transform(dataset_atencao['attention'])\n",
        "\n",
        "# Mostra o mapeamento das categorias\n",
        "print(f\"\\nMapeamento das categorias após codificação:\")\n",
        "categorias_originais = codificador_target.classes_\n",
        "for i, categoria in enumerate(categorias_originais):\n",
        "    print(f\"  {categoria} -> {i}\")\n",
        "\n",
        "print(f\"\\nDistribuição após codificação:\")\n",
        "print(dataset_codificado['attention'].value_counts().sort_index())\n",
        "\n",
        "# Separação das variáveis independentes (features) e dependente (target)\n",
        "variavel_target = dataset_codificado['attention']  # Variável a ser predita\n",
        "features_selecionadas = dataset_codificado[['solutions', 'score']]  # Features para predição\n",
        "\n",
        "print(f\"\\n=== INFORMAÇÕES DAS VARIÁVEIS ===\")\n",
        "print(f\"Target: 'attention' (níveis de atenção)\")\n",
        "print(f\"Features: {list(features_selecionadas.columns)} (soluções e pontuação)\")\n",
        "print(f\"Formato das features: {features_selecionadas.shape}\")\n",
        "print(f\"Formato do target: {variavel_target.shape}\")\n",
        "\n",
        "# Normalização das features usando MinMaxScaler\n",
        "# Transforma os valores para escala 0-1, importante para algoritmos sensíveis à escala (especialmente KNN)\n",
        "normalizador = MinMaxScaler()\n",
        "features_normalizadas_array = normalizador.fit_transform(features_selecionadas)\n",
        "\n",
        "# Criação de DataFrame com dados normalizados, preservando nomes das colunas\n",
        "features_normalizadas = pd.DataFrame(\n",
        "    features_normalizadas_array,\n",
        "    columns=features_selecionadas.columns\n",
        ")\n",
        "\n",
        "print(f\"\\n=== NORMALIZAÇÃO DOS DADOS ===\")\n",
        "print(\"Estatísticas antes da normalização:\")\n",
        "print(features_selecionadas.describe())\n",
        "print(\"\\nEstatísticas após normalização:\")\n",
        "print(features_normalizadas.describe())\n",
        "\n",
        "# Divisão dos dados em conjuntos de treino (70%) e teste (30%)\n",
        "# random_state=42 garante reprodutibilidade dos resultados\n",
        "X_treino, X_teste, y_treino, y_teste = train_test_split(\n",
        "    features_normalizadas,\n",
        "    variavel_target,\n",
        "    test_size=0.3,\n",
        "    random_state=42,\n",
        "    stratify=variavel_target  # Mantém proporção das classes nos conjuntos\n",
        ")\n",
        "\n",
        "print(f\"\\n=== DIVISÃO DOS DADOS ===\")\n",
        "print(f\"Dados de treino: {X_treino.shape[0]} amostras\")\n",
        "print(f\"Dados de teste: {X_teste.shape[0]} amostras\")\n",
        "print(f\"Distribuição no treino:\")\n",
        "print(y_treino.value_counts().sort_index())\n",
        "print(f\"Distribuição no teste:\")\n",
        "print(y_teste.value_counts().sort_index())\n",
        "\n",
        "# === TREINAMENTO DOS MODELOS DE CLASSIFICAÇÃO ===\n",
        "\n",
        "print(\"\\n=== TREINAMENTO DOS MODELOS ===\")\n",
        "\n",
        "# 1. Modelo de Regressão Logística\n",
        "# Algoritmo linear que usa função logística para classificação\n",
        "modelo_regressao_logistica = LogisticRegression(random_state=42, max_iter=1000)\n",
        "modelo_regressao_logistica.fit(X_treino, y_treino)\n",
        "print(\"✓ Regressão Logística treinada\")\n",
        "\n",
        "# 2. Modelo de Árvore de Decisão\n",
        "# Algoritmo baseado em regras que cria uma estrutura de árvore\n",
        "modelo_arvore_decisao = DecisionTreeClassifier(random_state=42)\n",
        "modelo_arvore_decisao.fit(X_treino, y_treino)\n",
        "print(\"✓ Árvore de Decisão treinada\")\n",
        "\n",
        "# 3. Modelo K-Nearest Neighbors (KNN)\n",
        "# Algoritmo que classifica baseado na classe dos k vizinhos mais próximos\n",
        "modelo_knn = KNeighborsClassifier(n_neighbors=5)\n",
        "modelo_knn.fit(X_treino, y_treino)\n",
        "print(\"✓ KNN treinado\")\n",
        "\n",
        "# === PREDIÇÕES NOS DADOS DE TESTE ===\n",
        "\n",
        "predicoes_regressao_logistica = modelo_regressao_logistica.predict(X_teste)\n",
        "predicoes_arvore_decisao = modelo_arvore_decisao.predict(X_teste)\n",
        "predicoes_knn = modelo_knn.predict(X_teste)\n",
        "\n",
        "# === AVALIAÇÃO DOS MODELOS ===\n",
        "\n",
        "# Cálculo da acurácia para cada modelo\n",
        "acuracia_regressao_logistica = accuracy_score(y_teste, predicoes_regressao_logistica)\n",
        "acuracia_arvore_decisao = accuracy_score(y_teste, predicoes_arvore_decisao)\n",
        "acuracia_knn = accuracy_score(y_teste, predicoes_knn)\n",
        "\n",
        "# === EXIBIÇÃO DOS RESULTADOS ===\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"           RESULTADOS DOS MODELOS\")\n",
        "print(\"=\"*50)\n",
        "print(f\"🤖 Regressão Logística: {acuracia_regressao_logistica*100:.2f}%\")\n",
        "print(f\"🌳 Árvore de Decisão:   {acuracia_arvore_decisao*100:.2f}%\")\n",
        "print(f\"👥 KNN (k=5):           {acuracia_knn*100:.2f}%\")\n",
        "\n",
        "# Identificação do melhor modelo\n",
        "modelos_resultados = {\n",
        "    'Regressão Logística': acuracia_regressao_logistica,\n",
        "    'Árvore de Decisão': acuracia_arvore_decisao,\n",
        "    'KNN': acuracia_knn\n",
        "}\n",
        "\n",
        "melhor_modelo_nome = max(modelos_resultados, key=modelos_resultados.get)\n",
        "melhor_acuracia = modelos_resultados[melhor_modelo_nome]\n",
        "\n",
        "print(f\"\\n🏆 MELHOR MODELO: {melhor_modelo_nome}\")\n",
        "print(f\"📊 ACURÁCIA: {melhor_acuracia*100:.2f}%\")\n",
        "\n",
        "# === ANÁLISE DETALHADA DO MELHOR MODELO ===\n",
        "\n",
        "print(f\"\\n\" + \"=\"*50)\n",
        "print(f\"      ANÁLISE DETALHADA - {melhor_modelo_nome.upper()}\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Seleciona as predições e o modelo do melhor resultado\n",
        "if melhor_modelo_nome == 'Regressão Logística':\n",
        "    melhores_predicoes = predicoes_regressao_logistica\n",
        "    melhor_modelo_obj = modelo_regressao_logistica\n",
        "elif melhor_modelo_nome == 'Árvore de Decisão':\n",
        "    melhores_predicoes = predicoes_arvore_decisao\n",
        "    melhor_modelo_obj = modelo_arvore_decisao\n",
        "else:\n",
        "    melhores_predicoes = predicoes_knn\n",
        "    melhor_modelo_obj = modelo_knn\n",
        "\n",
        "# Relatório de classificação com métricas detalhadas\n",
        "print(\"\\n📋 RELATÓRIO DE CLASSIFICAÇÃO:\")\n",
        "nomes_classes = [f\"Classe_{i} ({cat})\" for i, cat in enumerate(codificador_target.classes_)]\n",
        "print(classification_report(\n",
        "    y_teste,\n",
        "    melhores_predicoes,\n",
        "    target_names=nomes_classes\n",
        "))\n",
        "\n",
        "# Matriz de confusão\n",
        "print(\"\\n🎯 MATRIZ DE CONFUSÃO:\")\n",
        "matriz_confusao = confusion_matrix(y_teste, melhores_predicoes)\n",
        "print(\"   Pred:  \", end=\"\")\n",
        "for i in range(len(codificador_target.classes_)):\n",
        "    print(f\"{codificador_target.classes_[i]:>8}\", end=\"\")\n",
        "print()\n",
        "for i, linha in enumerate(matriz_confusao):\n",
        "    print(f\"Real {codificador_target.classes_[i]:>4}: \", end=\"\")\n",
        "    for valor in linha:\n",
        "        print(f\"{valor:>8}\", end=\"\")\n",
        "    print()\n",
        "\n",
        "# Análise de importância das features (se disponível)\n",
        "if hasattr(melhor_modelo_obj, 'feature_importances_'):\n",
        "    print(f\"\\n📈 IMPORTÂNCIA DAS FEATURES:\")\n",
        "    importancias = melhor_modelo_obj.feature_importances_\n",
        "    for feature, importancia in zip(features_selecionadas.columns, importancias):\n",
        "        print(f\"  {feature}: {importancia:.4f} ({importancia*100:.1f}%)\")\n",
        "elif hasattr(melhor_modelo_obj, 'coef_'):\n",
        "    print(f\"\\n📈 COEFICIENTES DO MODELO:\")\n",
        "    coeficientes = melhor_modelo_obj.coef_[0]\n",
        "    for feature, coef in zip(features_selecionadas.columns, coeficientes):\n",
        "        print(f\"  {feature}: {coef:.4f}\")\n",
        "\n",
        "# === INSIGHTS E RECOMENDAÇÕES ===\n",
        "print(f\"\\n\" + \"=\"*50)\n",
        "print(\"           INSIGHTS E RECOMENDAÇÕES\")\n",
        "print(\"=\"*50)\n",
        "print(\"💡 OBSERVAÇÕES:\")\n",
        "print(\"  • Dataset de atenção com features 'solutions' e 'score'\")\n",
        "print(\"  • Normalização MinMaxScaler aplicada (importante para KNN)\")\n",
        "print(\"  • Divisão estratificada mantém proporção das classes\")\n",
        "print(\"  • LabelEncoder usado para converter categorias em números\")\n",
        "\n",
        "print(\"\\n🔧 POSSÍVEIS MELHORIAS:\")\n",
        "print(\"  • Testar diferentes valores de k para KNN\")\n",
        "print(\"  • Aplicar validação cruzada para resultados mais robustos\")\n",
        "print(\"  • Considerar feature engineering adicional\")\n",
        "print(\"  • Avaliar outras métricas além da acurácia\")\n",
        "print(\"  • Testar algoritmos ensemble (Random Forest, etc.)\")\n",
        "\n",
        "print(f\"\\n⚠️  LIMITAÇÕES:\")\n",
        "print(\"  • Apenas 2 features utilizadas\")\n",
        "print(\"  • Avaliação baseada somente em acurácia\")\n",
        "print(\"  • Sem otimização de hiperparâmetros\")"
      ],
      "metadata": {
        "id": "ToZSK-uW2g0U",
        "outputId": "7cf33505-5f2f-4ad4-c7bd-407070a8ebbb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X shape: (60, 2)\n",
            "y shape: (60,)\n",
            "Acurácia Regressão Logística: 83.33%\n",
            "Acurácia Árvore de Decisão: 72.22%\n",
            "Acurácia KNN: 61.11%\n"
          ]
        }
      ]
    }
  ]
}